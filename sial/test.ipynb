{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75f83dbe-aaaf-41da-9f0d-c8cbe7ad8196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import get_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98f550de-ac6f-4e0d-a067-b044596fbec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sial.crosser import Crosser\n",
    "from sial.inferer import Inferer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c8c8b51-3078-4a34-909d-178fa634c1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_xy(\n",
    "    model,\n",
    "    iv_corr,\n",
    "    n_obs):\n",
    "    n_ivs = 10\n",
    "    mean = np.zeros((n_ivs,))\n",
    "    cov = np.block([[(iv_corr * np.ones((n_ivs - 3, n_ivs - 3)) + \n",
    "         (1 - iv_corr) * np.eye(n_ivs - 3)), np.zeros((7, 3))],\n",
    "                    [np.zeros((3, 7)), np.eye(3)]])\n",
    "    x = np.random.multivariate_normal(\n",
    "      mean = mean, \n",
    "      cov = cov, \n",
    "      size = n_obs)\n",
    "    if model == \"linear\":\n",
    "        coef = np.array([.1, .2, .3, .4]).reshape(4, -1)\n",
    "        cov_signal = cov[0:4, 0:4]\n",
    "        error_var = 1 - (coef.T @ cov_signal @ coef).item()\n",
    "        x_signal = x[:,0:4]\n",
    "    else:\n",
    "        coef = np.array([.3, .3, .3, .4]).reshape(4, -1)\n",
    "        sd_quad = np.sqrt(2)\n",
    "        sd_prod = np.sqrt(1 + iv_corr**2)\n",
    "        a = (2 * (iv_corr**2)) / (sd_quad * sd_quad)\n",
    "        b = (2 * (iv_corr**2)) / (sd_quad * sd_prod)\n",
    "        cov_signal = np.array(\n",
    "            [[ 1.  ,  0.  , 0.  ,  0.  ],\n",
    "             [ 0.  ,  1.  ,  a,  b],\n",
    "             [0.  ,  a,  1.  ,  b],\n",
    "             [ 0.  ,  b,  b,  1.  ]])\n",
    "        error_var = 1 - (coef.T @ cov_signal @ coef).item()\n",
    "        x_signal = np.concatenate(\n",
    "            (x[:,0:1], \n",
    "             (x[:,0:1]**2)  / sd_quad, \n",
    "             (x[:,1:2]**2) / sd_quad,\n",
    "             (x[:,2:3] * x[:,3:4]) / sd_prod), \n",
    "            axis = 1)\n",
    "    error = np.random.normal(\n",
    "      loc = 0.0, \n",
    "      scale = np.sqrt(error_var), \n",
    "      size = (n_obs, ))\n",
    "    y = (x_signal @ coef).reshape(-1,) + error\n",
    "    r2 = 1 - error_var\n",
    "    return x, y, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78e26191-39b3-4fe1-97e4-17016990d0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, r2 = gen_xy(\n",
    "        model = \"linear\",\n",
    "        iv_corr = .3,\n",
    "        n_obs= 200)\n",
    "removed_column = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "58eaa6c5-4bc4-4e6a-a00e-17b5dd06ec81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age    race     sex income\n",
      "0   50   White    male  <=50K\n",
      "1   38   White    male  <=50K\n",
      "2   53   Black    male  <=50K\n",
      "3   28   Black  female  <=50K\n",
      "4   37   White  female  <=50K\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:/Users/tommy/OneDrive/桌面/adult.csv\", names=[\n",
    "    'age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status',\n",
    "    'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss',\n",
    "    'hours-per-week', 'native-country', 'income'\n",
    "], skiprows=1, usecols=['age', 'sex', 'race','income'])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "f2918bde-38a1-4665-bc05-0342c75b0649",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['income'] = df['income'].map({'<=50K': 0, '>50K': 1})\n",
    "removed_column = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6a57a321-ef9a-4422-ae33-e6001b9b0152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "32555    0\n",
      "32556    1\n",
      "32557    0\n",
      "32558    0\n",
      "32559    1\n",
      "Name: income, Length: 32560, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['income'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "6ceb3ba6-f3a4-4971-b369-e073ee173690",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('income', axis=1).to_numpy()\n",
    "y=df['income'].to_numpy()\n",
    "numeric_features = [list(df.columns).index('age')]\n",
    "categorical_features_1 = [list(df.columns).index('race'), list(df.columns).index('sex')]\n",
    "categorical_features_2 = [list(df.columns).index('race')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "11666e30-d94f-4661-b915-ec89199381e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "X_new=df['sex'].map({'female': 1, 'male': 0}).to_numpy()\n",
    "print(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "2c8d91d2-c08a-4465-8551-22d8febecaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "preprocessor_1 = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features_1)\n",
    "    ])\n",
    "preprocessor_2 = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features_2)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f16e7742-e13a-47dd-b1e6-036342fa77e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold, RepeatedKFold, ShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "splitter = RepeatedKFold(\n",
    "    n_splits = 4, \n",
    "    n_repeats = 2, \n",
    "    random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c4d2c1e2-e88f-4893-a9a6-9d31f590592a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = Crosser(\n",
    "    GridSearchCV(\n",
    "            estimator = Pipeline(\n",
    "                [('preprocessor', preprocessor_1),\n",
    "                 ('estimator', RandomForestRegressor(max_samples = .5))]), \n",
    "            param_grid = {\n",
    "                \"estimator__max_features\": [3, 6, 9]}, \n",
    "            cv = 5),\n",
    "    cv = splitter,\n",
    "    scoring = \"neg_mean_squared_error\")\n",
    "sampler = Crosser(\n",
    "    GridSearchCV(\n",
    "            estimator = Pipeline(\n",
    "                [('preprocessor', preprocessor_2),\n",
    "                 ('estimator', RandomForestRegressor(max_samples = .5))]), \n",
    "            param_grid = {\n",
    "                \"estimator__max_features\": [3, 6, 9]}, \n",
    "            cv = 5),\n",
    "    cv = splitter,\n",
    "    scoring = \"neg_mean_squared_error\")\n",
    "competitor = Crosser(\n",
    "    GridSearchCV(\n",
    "            estimator = Pipeline(\n",
    "                [('preprocessor', preprocessor_2),\n",
    "                 ('estimator', RandomForestRegressor(max_samples = .5))]), \n",
    "            param_grid = {\n",
    "                \"estimator__max_features\": [3, 6, 9]}, \n",
    "            cv = 5),\n",
    "    cv = splitter,\n",
    "    scoring = \"neg_mean_squared_error\")\n",
    "_ = learner.fit(X, y)\n",
    "_ = sampler.fit(\n",
    "    np.delete(X, removed_column, axis = 1), X_new)\n",
    "_ = competitor.fit(\n",
    "    np.delete(X, removed_column, axis = 1), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "00b1e42e-dfdc-43bd-9f09-7f3e8744eb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: GridSearchCV\n",
      "Cross-Validator: RepeatedKFold (n_repeats=2, n_folds=4)\n",
      "Scoring Function: Neg Mean Squared Error (reverse=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_score</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>repeat</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.146317</td>\n",
       "      <td>-0.151055</td>\n",
       "      <td>-0.155429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.146511</td>\n",
       "      <td>-0.151030</td>\n",
       "      <td>-0.155679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        val_score  train_score  test_score\n",
       "repeat                                    \n",
       "0        0.146317    -0.151055   -0.155429\n",
       "1        0.146511    -0.151030   -0.155679"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.summarize(combine = False, cross_fit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "8bd848da-ca84-4683-8cda-56d059ac29ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'removed_column' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[150], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m crt \u001b[38;5;241m=\u001b[39m \u001b[43mInferer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCRT\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m _ \u001b[38;5;241m=\u001b[39m crt\u001b[38;5;241m.\u001b[39minfer()\n\u001b[0;32m      6\u001b[0m crt\u001b[38;5;241m.\u001b[39msummarize(cross_fit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\Users\\CCY\\sial\\sial\\inferer.py:530\u001b[0m, in \u001b[0;36mInferer.__init__\u001b[1;34m(self, learner, remover, algorithm, loss_func, infer_type, n_copies, double_split, perturb_size, n_permutations, random_state, removed_column)\u001b[0m\n\u001b[0;32m    528\u001b[0m         n_permutations \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2000\u001b[39m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m removed_column \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 530\u001b[0m     removed_column \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_removed_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremover\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m \u001b[38;5;241m=\u001b[39m CIT\n\u001b[0;32m    532\u001b[0m CIT\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    533\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    534\u001b[0m     learner, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    541\u001b[0m     random_state \u001b[38;5;241m=\u001b[39m random_state,\n\u001b[0;32m    542\u001b[0m     removed_column \u001b[38;5;241m=\u001b[39m removed_column)\n",
      "File \u001b[1;32mC:\\Users\\CCY\\sial\\sial\\inferer.py:267\u001b[0m, in \u001b[0;36mBaseInferer._removed_column\u001b[1;34m(self, learner, remover)\u001b[0m\n\u001b[0;32m    265\u001b[0m         removed_column \u001b[38;5;241m=\u001b[39m col\n\u001b[0;32m    266\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mremoved_column\u001b[49m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: cannot access local variable 'removed_column' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "crt = Inferer(\n",
    "    learner, \n",
    "    sampler,\n",
    "    \"CRT\" )\n",
    "_ = crt.infer()\n",
    "crt.summarize(cross_fit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "234516ef-44d3-47e2-87f4-56948f0f6a0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'removed_column' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[105], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cpi \u001b[38;5;241m=\u001b[39m \u001b[43mInferer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCPI\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43minfer_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnormality\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_copies\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m _ \u001b[38;5;241m=\u001b[39m cpi\u001b[38;5;241m.\u001b[39minfer()\n\u001b[0;32m      8\u001b[0m cpi\u001b[38;5;241m.\u001b[39msummarize(cross_fit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\Users\\CCY\\sial\\sial\\inferer.py:530\u001b[0m, in \u001b[0;36mInferer.__init__\u001b[1;34m(self, learner, remover, algorithm, loss_func, infer_type, n_copies, double_split, perturb_size, n_permutations, random_state, removed_column)\u001b[0m\n\u001b[0;32m    528\u001b[0m         n_permutations \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2000\u001b[39m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m removed_column \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 530\u001b[0m     removed_column \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_removed_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremover\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m \u001b[38;5;241m=\u001b[39m CIT\n\u001b[0;32m    532\u001b[0m CIT\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    533\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    534\u001b[0m     learner, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    541\u001b[0m     random_state \u001b[38;5;241m=\u001b[39m random_state,\n\u001b[0;32m    542\u001b[0m     removed_column \u001b[38;5;241m=\u001b[39m removed_column)\n",
      "File \u001b[1;32mC:\\Users\\CCY\\sial\\sial\\inferer.py:267\u001b[0m, in \u001b[0;36mBaseInferer._removed_column\u001b[1;34m(self, learner, remover)\u001b[0m\n\u001b[0;32m    265\u001b[0m         removed_column \u001b[38;5;241m=\u001b[39m col\n\u001b[0;32m    266\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mremoved_column\u001b[49m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: cannot access local variable 'removed_column' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "cpi = Inferer(\n",
    "    learner, \n",
    "    sampler,\n",
    "    \"CPI\",\n",
    "    infer_type = \"normality\",\n",
    "    n_copies = 1)\n",
    "_ = cpi.infer()\n",
    "cpi.summarize(cross_fit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ff2067b6-c41f-408f-b060-d9bf603b2eb0",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'removed_column' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[106], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cpi \u001b[38;5;241m=\u001b[39m \u001b[43mInferer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCPI\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43minfer_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpermutation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_copies\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m _ \u001b[38;5;241m=\u001b[39m cpi\u001b[38;5;241m.\u001b[39minfer()\n\u001b[0;32m      8\u001b[0m cpi\u001b[38;5;241m.\u001b[39msummarize(cross_fit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\Users\\CCY\\sial\\sial\\inferer.py:530\u001b[0m, in \u001b[0;36mInferer.__init__\u001b[1;34m(self, learner, remover, algorithm, loss_func, infer_type, n_copies, double_split, perturb_size, n_permutations, random_state, removed_column)\u001b[0m\n\u001b[0;32m    528\u001b[0m         n_permutations \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2000\u001b[39m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m removed_column \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 530\u001b[0m     removed_column \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_removed_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremover\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m \u001b[38;5;241m=\u001b[39m CIT\n\u001b[0;32m    532\u001b[0m CIT\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    533\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    534\u001b[0m     learner, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    541\u001b[0m     random_state \u001b[38;5;241m=\u001b[39m random_state,\n\u001b[0;32m    542\u001b[0m     removed_column \u001b[38;5;241m=\u001b[39m removed_column)\n",
      "File \u001b[1;32mC:\\Users\\CCY\\sial\\sial\\inferer.py:267\u001b[0m, in \u001b[0;36mBaseInferer._removed_column\u001b[1;34m(self, learner, remover)\u001b[0m\n\u001b[0;32m    265\u001b[0m         removed_column \u001b[38;5;241m=\u001b[39m col\n\u001b[0;32m    266\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mremoved_column\u001b[49m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: cannot access local variable 'removed_column' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "cpi = Inferer(\n",
    "    learner, \n",
    "    sampler,\n",
    "    \"CPI\",\n",
    "    infer_type = \"permutation\",\n",
    "    n_copies = 100)\n",
    "_ = cpi.infer()\n",
    "cpi.summarize(cross_fit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4df1a82e-03a1-48f7-829f-4c0c8a266775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm: PIE (double_split=True, perturb_size=None)\n",
      "Inference Type: Normality (n_copies=None, n_permutations=None)\n",
      "Loss Function: Mean Squared Error (reverse=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>estimate</th>\n",
       "      <th>std_error</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split</th>\n",
       "      <th>repeat</th>\n",
       "      <th>fold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>-0.303159</td>\n",
       "      <td>0.272950</td>\n",
       "      <td>0.133355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>-0.479834</td>\n",
       "      <td>0.389755</td>\n",
       "      <td>0.109140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>0.069110</td>\n",
       "      <td>0.168031</td>\n",
       "      <td>0.659571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>0</th>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>-0.728386</td>\n",
       "      <td>0.291135</td>\n",
       "      <td>0.006177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>-0.140964</td>\n",
       "      <td>0.203148</td>\n",
       "      <td>0.243874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>0.016049</td>\n",
       "      <td>0.328007</td>\n",
       "      <td>0.519512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>-0.309677</td>\n",
       "      <td>0.399886</td>\n",
       "      <td>0.219343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <th>1</th>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>0.042280</td>\n",
       "      <td>0.190848</td>\n",
       "      <td>0.587662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   size  estimate  std_error   p_value\n",
       "split repeat fold                                     \n",
       "0     0      0       50 -0.303159   0.272950  0.133355\n",
       "1     0      1       50 -0.479834   0.389755  0.109140\n",
       "2     0      2       50  0.069110   0.168031  0.659571\n",
       "3     0      3       50 -0.728386   0.291135  0.006177\n",
       "4     1      0       50 -0.140964   0.203148  0.243874\n",
       "5     1      1       50  0.016049   0.328007  0.519512\n",
       "6     1      2       50 -0.309677   0.399886  0.219343\n",
       "7     1      3       50  0.042280   0.190848  0.587662"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pie = Inferer(\n",
    "    learner, \n",
    "    competitor,\n",
    "    \"PIE\",\n",
    "    infer_type = \"normality\")\n",
    "_ = pie.infer()\n",
    "pie.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "257099ba-8efc-4c54-87ad-f42e2c8bc9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm: PIE (double_split=True, perturb_size=None)\n",
      "Inference Type: Permutation (n_copies=None, n_permutations=2000)\n",
      "Loss Function: Mean Squared Error (reverse=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>estimate</th>\n",
       "      <th>std_error</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gmean</th>\n",
       "      <td>200.0</td>\n",
       "      <td>-0.229322</td>\n",
       "      <td>0.143393</td>\n",
       "      <td>0.127615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>200.0</td>\n",
       "      <td>-0.229322</td>\n",
       "      <td>0.143393</td>\n",
       "      <td>0.283500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q1</th>\n",
       "      <td>200.0</td>\n",
       "      <td>-0.229322</td>\n",
       "      <td>0.143393</td>\n",
       "      <td>0.275500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>200.0</td>\n",
       "      <td>-0.229322</td>\n",
       "      <td>0.143393</td>\n",
       "      <td>0.016000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmean</th>\n",
       "      <td>200.0</td>\n",
       "      <td>-0.229322</td>\n",
       "      <td>0.143393</td>\n",
       "      <td>0.029296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hommel</th>\n",
       "      <td>200.0</td>\n",
       "      <td>-0.229322</td>\n",
       "      <td>0.143393</td>\n",
       "      <td>0.024000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cauchy</th>\n",
       "      <td>200.0</td>\n",
       "      <td>-0.229322</td>\n",
       "      <td>0.143393</td>\n",
       "      <td>0.015655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         size  estimate  std_error   p_value\n",
       "method                                      \n",
       "gmean   200.0 -0.229322   0.143393  0.127615\n",
       "median  200.0 -0.229322   0.143393  0.283500\n",
       "q1      200.0 -0.229322   0.143393  0.275500\n",
       "min     200.0 -0.229322   0.143393  0.016000\n",
       "hmean   200.0 -0.229322   0.143393  0.029296\n",
       "hommel  200.0 -0.229322   0.143393  0.024000\n",
       "cauchy  200.0 -0.229322   0.143393  0.015655"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pie = Inferer(\n",
    "    learner, \n",
    "    competitor,\n",
    "    \"PIE\",\n",
    "    infer_type = \"permutation\")\n",
    "_ = pie.infer()\n",
    "pie.summarize(\n",
    "    cross_fit = True,\n",
    "combine=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec6f393-2e4f-464e-95e1-ceac9dcd7dfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
