{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27c7d395-c2bc-4f1a-b5fb-1cd03cadb885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numbers\n",
    "from numpy import random \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit, KFold\n",
    "from sklearn.metrics import get_scorer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.base import clone\n",
    "from joblib import Parallel, delayed\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b031913-520f-434d-97ee-14a6236cfa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_xy(\n",
    "    model,\n",
    "    iv_corr,\n",
    "    n_obs):\n",
    "    n_ivs = 10\n",
    "    mean = np.zeros((n_ivs,))\n",
    "    cov = np.block([[(iv_corr * np.ones((n_ivs - 3, n_ivs - 3)) + \n",
    "         (1 - iv_corr) * np.eye(n_ivs - 3)), np.zeros((7, 3))],\n",
    "                    [np.zeros((3, 7)), np.eye(3)]])\n",
    "    x = random.multivariate_normal(\n",
    "      mean = mean, \n",
    "      cov = cov, \n",
    "      size = n_obs)\n",
    "    if model == \"linear\":\n",
    "        coef = np.array([.1, .2, .3, .4]).reshape(4, -1)\n",
    "        cov_signal = cov[0:4, 0:4]\n",
    "        error_var = 1 - (coef.T @ cov_signal @ coef).item()\n",
    "        x_signal = x[:,0:4]\n",
    "    else:\n",
    "        coef = np.array([.3, .3, .3, .4]).reshape(4, -1)\n",
    "        sd_quad = np.sqrt(2)\n",
    "        sd_prod = np.sqrt(1 + iv_corr**2)\n",
    "        a = (2 * (iv_corr**2)) / (sd_quad * sd_quad)\n",
    "        b = (2 * (iv_corr**2)) / (sd_quad * sd_prod)\n",
    "        cov_signal = np.array(\n",
    "            [[ 1.  ,  0.  , 0.  ,  0.  ],\n",
    "             [ 0.  ,  1.  ,  a,  b],\n",
    "             [0.  ,  a,  1.  ,  b],\n",
    "             [ 0.  ,  b,  b,  1.  ]])\n",
    "        error_var = 1 - (coef.T @ cov_signal @ coef).item()\n",
    "        x_signal = np.concatenate(\n",
    "            (x[:,0:1], \n",
    "             (x[:,0:1]**2)  / sd_quad, \n",
    "             (x[:,1:2]**2) / sd_quad,\n",
    "             (x[:,2:3] * x[:,3:4]) / sd_prod), \n",
    "            axis = 1)\n",
    "    error = random.normal(\n",
    "      loc = 0.0, \n",
    "      scale = np.sqrt(error_var), \n",
    "      size = (n_obs, ))\n",
    "    y = (x_signal @ coef).reshape(-1,) + error\n",
    "    r2 = 1 - error_var\n",
    "    return x, y, r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f4cc9013-7e1d-425f-a996-86135b8fb867",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RPT():\n",
    "    def __init__(\n",
    "        self,\n",
    "        learner,\n",
    "        samplers,\n",
    "        metric,\n",
    "        mode = \"x\",\n",
    "        splitter = 0.5,\n",
    "        n_samples = 1000,\n",
    "        n_jobs = None,\n",
    "        random_state = None,\n",
    "        greater_is_better = False,\n",
    "        fit_learner = True,\n",
    "        fit_samplers = True):\n",
    "\n",
    "        if not (hasattr(learner, \"fit\") and hasattr(learner, \"predict\")):\n",
    "            raise TypeError(\"`learner` must have `fit` and `predict` methods.\")\n",
    "\n",
    "        if splitter is not None:\n",
    "            if isinstance(splitter, numbers.Integral):\n",
    "                splitter = KFold(\n",
    "                    n_splits = splitter, \n",
    "                    shuffle = True, \n",
    "                    random_state = random_state)\n",
    "            elif isinstance(splitter, numbers.Real):\n",
    "                splitter = ShuffleSplit(\n",
    "                    n_splits = 1, \n",
    "                    test_size = splitter, \n",
    "                    random_state = random_state)\n",
    "        \n",
    "        self.learner = learner\n",
    "        self.samplers = samplers\n",
    "        self.metric = metric\n",
    "        self.greater_is_better = greater_is_better\n",
    "        self.mode = mode\n",
    "        self.splitter = splitter\n",
    "        self.n_samples = n_samples\n",
    "        self.n_jobs = n_jobs\n",
    "        self.random_state = random_state\n",
    "        self.fit_learner = fit_learner\n",
    "        self.fit_samplers = fit_samplers\n",
    "    \n",
    "    def infer(\n",
    "        self, x, y):\n",
    "        if self.splitter is None:\n",
    "            train_index = np.arange(len(x))\n",
    "            test_index = np.arange(len(x))\n",
    "            split_indices = ((train_index, test_index))\n",
    "        else:\n",
    "            split_indices = self.splitter.split(x)\n",
    "                \n",
    "        def cal_null_score_x(\n",
    "            learner, \n",
    "            metric, \n",
    "            x_test, \n",
    "            y_test, \n",
    "            feature,\n",
    "            dv_pred_test, \n",
    "            dv_res_test,\n",
    "            seed):\n",
    "            rng = np.random.RandomState(seed)\n",
    "            x_perm = np.copy(x_test)\n",
    "            x_perm[:, feature] = dv_pred_test + rng.permutation(dv_res_test)\n",
    "            y_perm = learner.predict(x_perm)\n",
    "            null_score = metric(y_test, y_perm)\n",
    "            return null_score\n",
    "\n",
    "        def cal_null_score_y(\n",
    "            metric, \n",
    "            y_pred_test, \n",
    "            dv_pred_test, \n",
    "            dv_res_test,\n",
    "            seed):\n",
    "            rng = np.random.RandomState(seed)\n",
    "            y_perm = dv_pred_test + rng.permutation(dv_res_test)\n",
    "            null_score = metric(y_perm, y_pred_test)\n",
    "            return null_score\n",
    "        \n",
    "        learner_dict = {}\n",
    "        samplers_dict = {}\n",
    "        target_score_dict = {}\n",
    "        null_scores_dict = {}\n",
    "        for i, (train_index, test_index) in enumerate(split_indices):\n",
    "            x_train, y_train = x[train_index, :], y[train_index]\n",
    "            x_test, y_test = x[test_index, :], y[test_index]\n",
    "            learner_dict[i] = clone(self.learner)\n",
    "            if self.fit_learner:\n",
    "                _ = learner_dict[i].fit(x_train, y_train)\n",
    "            y_pred_test = learner_dict[i].predict(x_test)\n",
    "            target_score_dict[i] = self.metric(\n",
    "                y_test, y_pred_test)\n",
    "\n",
    "            samplers_dict[i] = {}\n",
    "            null_scores_dict[i] = {}\n",
    "            rng = np.random.RandomState(self.random_state)\n",
    "            for feature, sampler in self.samplers.items():\n",
    "                iv_train = np.delete(x_train, feature, 1)\n",
    "                iv_test = np.delete(x_test, feature, 1)\n",
    "                if self.mode == \"x\":\n",
    "                    dv_train = x_train[:, feature]\n",
    "                    dv_test = x_test[:, feature]\n",
    "                elif self.mode == \"y\":\n",
    "                    dv_train = y_train\n",
    "                    dv_test = y_test\n",
    "                if sampler is not None:\n",
    "                    samplers_dict[i][feature] = clone(sampler)\n",
    "                else:\n",
    "                    samplers_dict[i][feature] = None\n",
    "                if samplers_dict[i][feature] is not None:\n",
    "                    if self.fit_samplers:\n",
    "                        _ = samplers_dict[i][feature].fit(iv_train, dv_train)\n",
    "                    dv_pred_test = samplers_dict[i][feature].predict(iv_test)\n",
    "                else:\n",
    "                    dv_pred_test = np.zeros_like(dv_test)\n",
    "                dv_res_test = dv_test - dv_pred_test\n",
    "                \n",
    "                seeds = rng.randint(\n",
    "                    2**32 - 1, \n",
    "                    size = self.n_samples)               \n",
    "                if self.mode == \"x\":\n",
    "                    null_scores_dict[i][feature] = np.array(\n",
    "                        Parallel(n_jobs = self.n_jobs)(\n",
    "                            delayed(cal_null_score_x)(\n",
    "                                learner_dict[i], \n",
    "                                self.metric,\n",
    "                                x_test, \n",
    "                                y_test, \n",
    "                                feature,\n",
    "                                dv_pred_test, \n",
    "                                dv_res_test,\n",
    "                                seed) for seed in seeds))\n",
    "                elif self.mode == \"y\":\n",
    "                    null_scores_dict[i][feature] = np.array(\n",
    "                        Parallel(n_jobs = self.n_jobs)(\n",
    "                            delayed(cal_null_score_y)(\n",
    "                                self.metric,\n",
    "                                y_pred_test,\n",
    "                                dv_pred_test, \n",
    "                                dv_res_test,\n",
    "                                seed) for seed in seeds))\n",
    "        self._learner_dict = learner_dict\n",
    "        self._samplers_dict = samplers_dict\n",
    "        self._target_score_dict = target_score_dict\n",
    "        self._null_scores_dict = null_scores_dict\n",
    "\n",
    "    def all_scores(\n",
    "        self):\n",
    "        def tidy(\n",
    "            split, \n",
    "            target_score, \n",
    "            null_scores):\n",
    "            df = pd.DataFrame.from_dict(\n",
    "                null_scores, \n",
    "                orient = \"index\")\n",
    "            df[\"split\"] = split\n",
    "            df[\"target_score\"] = target_score\n",
    "            df.index.name = \"feature\"\n",
    "            df = df.reset_index()\n",
    "            df = df.melt(\n",
    "                id_vars = [\"split\", \"feature\", \"target_score\"], \n",
    "                var_name='sample', \n",
    "                value_name='null_score')\n",
    "            return df\n",
    "\n",
    "        all_scores = pd.concat(\n",
    "            [tidy(split, target_score, null_scores) \n",
    "             for (split, target_score), null_scores in zip(\n",
    "                 self._target_score_dict.items(), \n",
    "                 self._null_scores_dict.values())],\n",
    "            ignore_index = True)\n",
    "        return all_scores\n",
    "        \n",
    "    def pfi(\n",
    "        self):\n",
    "        all_scores = self.all_scores()\n",
    "        if self.greater_is_better:\n",
    "            all_scores[\"diff_score\"] = all_scores[\"target_score\"] - all_scores[\"null_score\"]\n",
    "        else:\n",
    "            all_scores[\"diff_score\"] = all_scores[\"null_score\"] - all_scores[\"target_score\"]\n",
    "        pfi = all_scores.groupby(\n",
    "            [\"feature\"]).apply(\n",
    "            lambda x: np.mean(x.diff_score))\n",
    "        return pfi\n",
    "\n",
    "    def pvalue(\n",
    "        self, \n",
    "        aggregate = None):\n",
    "        n_splits = len(self._learner_dict)\n",
    "        all_scores = self.all_scores()\n",
    "        if self.greater_is_better:\n",
    "            all_scores[\"diff_score\"] = all_scores[\"target_score\"] - all_scores[\"null_score\"]\n",
    "        else:\n",
    "            all_scores[\"diff_score\"] = all_scores[\"null_score\"] - all_scores[\"target_score\"]\n",
    "\n",
    "        if aggregate is None:\n",
    "            if n_splits == 1:\n",
    "                pvalue = all_scores.groupby(\n",
    "                    [\"feature\"]).apply(\n",
    "                    lambda x: np.mean(x.diff_score < 0))\n",
    "            else:\n",
    "                pvalue = all_scores.groupby(\n",
    "                    [\"split\", \"feature\"]).apply(\n",
    "                    lambda x: np.mean(x.diff_score < 0))\n",
    "        else:\n",
    "            if aggregate == \"bonferroni\":\n",
    "                pvalue = all_scores.groupby(\n",
    "                    [\"split\", \"feature\"]).apply(\n",
    "                    lambda x: np.mean(x.diff_score < 0)).groupby(\n",
    "                    [\"feature\"]).apply(\n",
    "                    lambda x: np.minimum(n_splits * np.min(x), 1))\n",
    "            elif aggregate == \"average\":\n",
    "                pvalue = all_scores.groupby(\n",
    "                    [\"split\", \"feature\"]).apply(\n",
    "                    lambda x: np.mean(x.diff_score < 0)).groupby(\n",
    "                    [\"feature\"]).apply(\n",
    "                    lambda x: np.minimum(2 * np.mean(x), 1))\n",
    "            elif aggregate == \"mimic\":\n",
    "                pvalue = all_scores.groupby(\n",
    "                    [\"feature\", \"sample\"]).apply(\n",
    "                    lambda x: np.sum(x.diff_score)).groupby(\n",
    "                    [\"feature\"]).apply(\n",
    "                    lambda x: np.mean(x < 0))\n",
    "            else:\n",
    "                raise ValueError(\"Value of `aggregate` is unrecognized.\")\n",
    "        return pvalue\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f415f0a5-869d-4898-9e98-0591f0ce0dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_one(\n",
    "    model, \n",
    "    iv_corr, \n",
    "    n_obs, \n",
    "    rep):\n",
    "    searchers = {\n",
    "        \"LR\":LinearRegression(),\n",
    "        \"KNN\":GridSearchCV(\n",
    "            estimator = KNeighborsRegressor(), \n",
    "            param_grid = {\n",
    "                \"n_neighbors\": [5, 10, 15, 20]}, \n",
    "            cv = n_splits, \n",
    "            n_jobs = n_jobs),\n",
    "        \"MLP\":GridSearchCV(\n",
    "            estimator = MLPRegressor(\n",
    "                max_iter = 5000), \n",
    "            param_grid = {\n",
    "                \"hidden_layer_sizes\": [(8,), (16,), (32,), (64,)]}, \n",
    "            cv = n_splits, \n",
    "            n_jobs = n_jobs),\n",
    "        \"DT\": GridSearchCV(\n",
    "            estimator = DecisionTreeRegressor(), \n",
    "            param_grid = {\n",
    "                \"min_samples_leaf\": [1, 2, 4, 8]}, \n",
    "            cv = n_splits, \n",
    "            n_jobs = n_jobs),\n",
    "        \"RF\":GridSearchCV(\n",
    "            estimator = RandomForestRegressor(), \n",
    "            param_grid = {\n",
    "                \"max_features\": [3, 6, 9]}, \n",
    "            cv = n_splits, \n",
    "            n_jobs = n_jobs)}\n",
    "    x, y, r2 = gen_xy(\n",
    "        model,\n",
    "        iv_corr,\n",
    "        n_obs)\n",
    "    columns = list(itertools.chain(\n",
    "        *[[\"Model\",\n",
    "           \"Corr\", \n",
    "           \"Sample Size\", \n",
    "           \"Rep\",\n",
    "           \"Algorithm\",\n",
    "           \"Mode\"],\n",
    "          [str(i + 1) for i in [0, 1, 2, 3, 4, 7]]]))\n",
    "    list_one = []\n",
    "    for algorithm, searcher in searchers.items():\n",
    "        for mode in [\"x\", \"y\", \"vanilla\"]:\n",
    "            condition = [model, iv_corr, n_obs, rep, algorithm, mode]\n",
    "            learner = clone(searcher)\n",
    "            if mode == \"vanilla\":\n",
    "                samplers = {feature: None\n",
    "                     for feature in [0, 1, 2, 3, 4, 7]}\n",
    "                mode = \"x\"\n",
    "            else:\n",
    "                samplers = {feature: clone(searcher) \n",
    "                     for feature in [0, 1, 2, 3, 4, 7]}\n",
    "            rpt = RPT(learner, \n",
    "              samplers, \n",
    "              metric = mean_squared_error, \n",
    "              mode = mode,\n",
    "              n_jobs = n_jobs)\n",
    "            rpt.infer(x, y)\n",
    "            pvalue = rpt.pvalue()\n",
    "            list_one.append(list(\n",
    "                itertools.chain(*[condition, pvalue])))\n",
    "    df_one = pd.DataFrame(\n",
    "            list_one, \n",
    "            columns = columns)\n",
    "    return df_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9e9b6c-719f-4a22-9af7-1e91c927b6a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: linear / Corr: 0.4 / Sample Size: 100\n",
      "Starting Time = 2023-12-15 08:39:56\n"
     ]
    }
   ],
   "source": [
    "models = [\"linear\", \"nonlinear\"]\n",
    "iv_corrs = [.3]\n",
    "n_obss = [100, 200, 400, 800]\n",
    "n_splits = 5\n",
    "n_jobs = 8\n",
    "n_reps = 1000\n",
    "np.random.seed(46)\n",
    "start_time = datetime.now()\n",
    "for model in models:\n",
    "    for iv_corr in iv_corrs:\n",
    "        for n_obs in n_obss:\n",
    "            print(\"Model:\", model, \"/\", \"Corr:\", iv_corr, \"/\", \"Sample Size:\", n_obs)\n",
    "            now = datetime.now()\n",
    "            start_time_i = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            print(\"Starting Time =\", start_time_i)\n",
    "            result = [do_one(\n",
    "                model, iv_corr, n_obs, rep) for rep in range(n_reps)]\n",
    "            result = pd.concat(result, ignore_index = True)\n",
    "            file_name = (\"result_\" + str(model) + \n",
    "                          \"_\" + str(iv_corr) +\n",
    "                         \"_\" + str(n_obs) + \".csv\")\n",
    "            result.to_csv(\"../results_i/\" + file_name, index = False)\n",
    "            now = datetime.now()\n",
    "            end_time_i = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            print(\"Ending Time =\", end_time_i)\n",
    "            print(\"----------------------------------------------\")\n",
    "end_time = datetime.now()\n",
    "delta_time = start_time - end_time\n",
    "print(\"Simulation Finished!!!!!\")\n",
    "print(\"Total Time (in Seconds) =\", abs(delta_time).seconds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
