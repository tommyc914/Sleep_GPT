{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59662b87-f10b-4fd6-8460-83f8b2bb53cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import check_cv\n",
    "from sklearn.base import is_classifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import get_scorer, check_scoring\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from scipy.special import xlogy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "824384cd-7b30-41d7-bd01-3d7ede661674",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gen_xy(\n",
    "    model,\n",
    "    iv_corr,\n",
    "    n_obs):\n",
    "    n_ivs = 10\n",
    "    mean = np.zeros((n_ivs,))\n",
    "    cov = np.block([[(iv_corr * np.ones((n_ivs - 3, n_ivs - 3)) + \n",
    "         (1 - iv_corr) * np.eye(n_ivs - 3)), np.zeros((7, 3))],\n",
    "                    [np.zeros((3, 7)), np.eye(3)]])\n",
    "    x = np.random.multivariate_normal(\n",
    "      mean = mean, \n",
    "      cov = cov, \n",
    "      size = n_obs)\n",
    "    if model == \"linear\":\n",
    "        coef = np.array([.1, .2, .3, .4]).reshape(4, -1)\n",
    "        cov_signal = cov[0:4, 0:4]\n",
    "        error_var = 1 - (coef.T @ cov_signal @ coef).item()\n",
    "        x_signal = x[:,0:4]\n",
    "    else:\n",
    "        coef = np.array([.3, .3, .3, .4]).reshape(4, -1)\n",
    "        sd_quad = np.sqrt(2)\n",
    "        sd_prod = np.sqrt(1 + iv_corr**2)\n",
    "        a = (2 * (iv_corr**2)) / (sd_quad * sd_quad)\n",
    "        b = (2 * (iv_corr**2)) / (sd_quad * sd_prod)\n",
    "        cov_signal = np.array(\n",
    "            [[ 1.  ,  0.  , 0.  ,  0.  ],\n",
    "             [ 0.  ,  1.  ,  a,  b],\n",
    "             [0.  ,  a,  1.  ,  b],\n",
    "             [ 0.  ,  b,  b,  1.  ]])\n",
    "        error_var = 1 - (coef.T @ cov_signal @ coef).item()\n",
    "        x_signal = np.concatenate(\n",
    "            (x[:,0:1], \n",
    "             (x[:,0:1]**2)  / sd_quad, \n",
    "             (x[:,1:2]**2) / sd_quad,\n",
    "             (x[:,2:3] * x[:,3:4]) / sd_prod), \n",
    "            axis = 1)\n",
    "    error = np.random.normal(\n",
    "      loc = 0.0, \n",
    "      scale = np.sqrt(error_var), \n",
    "      size = (n_obs, ))\n",
    "    y = (x_signal @ coef).reshape(-1,) + error\n",
    "    r2 = 1 - error_var\n",
    "    return x, y, r2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c096675-d58c-4854-9c74-01eb271a49ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEstimator():\n",
    "    def __init__(\n",
    "        self,\n",
    "        estimator,\n",
    "        cv = None\n",
    "    ):\n",
    "        self.estimator = estimator\n",
    "        self.cv = cv\n",
    "\n",
    "    def fit(\n",
    "        self, \n",
    "        X, \n",
    "        y\n",
    "    ):\n",
    "        cv = self.cv\n",
    "        cv = check_cv(\n",
    "            cv, y, \n",
    "            classifier = is_classifier(self.estimator))\n",
    "        cv_indexes = []\n",
    "        estimators = []\n",
    "        for train_index, test_index in cv.split(X):     \n",
    "            estimator = clone(self.estimator)\n",
    "            _ = estimator.fit(X[train_index,], y[train_index])\n",
    "            estimator = estimator\n",
    "            estimators.append(estimator)               \n",
    "            cv_indexes.append((train_index, test_index))\n",
    "        self.X_, self.y_ = X.copy(), y.copy()\n",
    "        self.estimators_ = estimators\n",
    "        self.cv_indexes_ = cv_indexes\n",
    "        self.n_splits_ = cv.get_n_splits()\n",
    "        if is_classifier(self.estimator):\n",
    "            label_binarizer = LabelBinarizer()\n",
    "            _ = label_binarizer.fit(y)\n",
    "            self.label_binarizer_ = label_binarizer\n",
    "        return self\n",
    "\n",
    "    def predict(\n",
    "        self, \n",
    "        X,\n",
    "        split = None\n",
    "    ):\n",
    "        if split is None:\n",
    "            preds = np.array(\n",
    "                [estimator.predict(X) \n",
    "                 for estimator in self.estimators_])\n",
    "            if is_classifier(self.estimator):\n",
    "                pred = np.apply_along_axis(\n",
    "                    lambda x: np.argmax(np.bincount(x)),\n",
    "                    axis = 0,\n",
    "                    arr = preds)\n",
    "            else:\n",
    "                pred = preds.mean(axis = 0)\n",
    "        else:\n",
    "            pred = self.estimators_[split].predict(X)\n",
    "        return pred\n",
    "\n",
    "    def predict_proba(\n",
    "        self, \n",
    "        X,\n",
    "        split = None\n",
    "    ):\n",
    "        if split is None:\n",
    "            preds = np.array(\n",
    "                [estimator.predict_proba(X)\n",
    "                 for estimator in self.estimators_])\n",
    "            pred = preds.mean(axis = 0)\n",
    "        else:\n",
    "            pred = self.estimators_[split].predict_proba(X)\n",
    "        return pred\n",
    "\n",
    "    def predict_log_proba(\n",
    "        self, \n",
    "        X,\n",
    "        split = None\n",
    "    ):\n",
    "        if split is None:\n",
    "            preds = np.array(\n",
    "                [estimator.predict_log_proba(X)\n",
    "                 for estimator in self.estimators_])\n",
    "            pred = preds.mean(axis = 0)\n",
    "        else:\n",
    "            pred = self.estimators_[split].predict_log_proba(X)\n",
    "        return pred\n",
    "            \n",
    "    def decision_function(\n",
    "        self, \n",
    "        X,\n",
    "        split = None\n",
    "    ):\n",
    "        if split is None:\n",
    "            preds = np.array(\n",
    "                [estimator.decision_function(X) \n",
    "                 for estimator in self.estimators_])\n",
    "            pred = preds.mean(axis = 0)\n",
    "        else:\n",
    "            pred = self.estimators_[split].decision_function(X)\n",
    "        return pred\n",
    "            \n",
    "    \n",
    "    def sample(\n",
    "        self,\n",
    "        X,\n",
    "        split = None,\n",
    "        n_repeats = None, \n",
    "        random_state = None\n",
    "    ):\n",
    "        rng = np.random.default_rng(random_state)\n",
    "        if is_classifier(self.estimator):\n",
    "            pred = self.predict_proba(X, split)\n",
    "            if n_repeats is None:            \n",
    "                rv = rng.multinomial(1, pred)\n",
    "                rv = self.label_binarizer_.inverse_transform(rv)\n",
    "            else:\n",
    "                rv = rng.multinomial(\n",
    "                    1, pred, (n_repeats, len(pred)))\n",
    "                rv = np.array(\n",
    "                    [self.label_binarizer_.inverse_transform(rv_i) \n",
    "                     for rv_i in rv])\n",
    "        else:\n",
    "            if split is None:\n",
    "                targets = self._targets()\n",
    "                preds = self._preds()\n",
    "                residual = np.concatenate(\n",
    "                    [target - pred \n",
    "                     for target, pred in zip(targets, preds)])\n",
    "            else:\n",
    "                train_index, test_index = self.cv_indexes_[split]\n",
    "                if hasattr(self.X_, \"iloc\"):\n",
    "                    feature = self.X_.iloc[test_index, :]\n",
    "                    target = self.y_.iloc[test_index]\n",
    "                else:\n",
    "                    feature = self.X_[test_index, :]\n",
    "                    target = self.y_[test_index]\n",
    "                pred = self.predict(feature, split)     \n",
    "                residual = target - pred\n",
    "            pred = self.predict(X, split)\n",
    "            if len(pred) > len(residual):\n",
    "                replace = True\n",
    "            else:\n",
    "                replace = False\n",
    "            if n_repeats is None:\n",
    "                rv = pred + rng.choice(residual, len(pred), replace)\n",
    "            else:\n",
    "                rv = pred + np.array(\n",
    "                    [rng.choice(residual, len(pred), replace) \n",
    "                     for repeat in range(n_repeats)])\n",
    "        return rv\n",
    "\n",
    "    def _features(\n",
    "        self\n",
    "    ):\n",
    "        features = []\n",
    "        for train_index, test_index in self.cv_indexes_:\n",
    "            if hasattr(self.X_, \"iloc\"):\n",
    "                feature = self.X_.iloc[test_index, :]\n",
    "            else:\n",
    "                feature = self.X_[test_index, :]\n",
    "            features.append(feature)\n",
    "        return features\n",
    "    \n",
    "    def _targets(\n",
    "        self,\n",
    "        binarize = None\n",
    "    ):\n",
    "        targets = []\n",
    "        for train_index, test_index in self.cv_indexes_:\n",
    "            if hasattr(self.y_, \"iloc\"):\n",
    "                target = self.y_.iloc[test_index]\n",
    "            else:\n",
    "                target = self.y_[test_index]\n",
    "            if is_classifier(self.estimator):\n",
    "                if binarize is True:\n",
    "                    target = self.label_binarizer_.transform(target)\n",
    "                    if target.shape[1] == 1:\n",
    "                        target = np.append(1 - target, target, axis=1)\n",
    "            targets.append(target)\n",
    "        return targets\n",
    "\n",
    "    def _preds(\n",
    "        self,\n",
    "        response_method = \"predict\"\n",
    "    ):\n",
    "        preds = []\n",
    "        for split, (train_index, test_index) in enumerate(self.cv_indexes_):\n",
    "            predict_func = getattr(self, response_method)\n",
    "            if hasattr(self.X_, \"iloc\"):\n",
    "                feature = self.X_.iloc[test_index, :]\n",
    "            else:\n",
    "                feature = self.X_[test_index, :]\n",
    "            pred = predict_func(feature, split)\n",
    "            preds.append(pred)\n",
    "        return preds\n",
    "\n",
    "    def _rvs(\n",
    "        self,\n",
    "        n_repeats = None,\n",
    "        random_state = None\n",
    "    ):\n",
    "        rvs = []\n",
    "        for split, (train_index, test_index) in enumerate(self.cv_indexes_):\n",
    "            if hasattr(self.X_, \"iloc\"):\n",
    "                feature = self.X_.iloc[test_index, :]\n",
    "            else:\n",
    "                feature = self.X_[test_index, :]\n",
    "            rv = self.sample(\n",
    "                feature, \n",
    "                split, \n",
    "                n_repeats,\n",
    "                random_state)\n",
    "            rvs.append(rv)\n",
    "        return rvs\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0da0854b-84cf-4a0d-9ef4-4af0edea40b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIT():\n",
    "    def __init__(\n",
    "        self, \n",
    "        learner,\n",
    "        remover,\n",
    "        column,\n",
    "        infer_method = \"perm\",\n",
    "        loss_func = None,\n",
    "        n_repeats = None,\n",
    "        random_state = None\n",
    "    ):\n",
    "        if loss_func is None:\n",
    "            if is_classifier(learner.estimator):\n",
    "                loss_func = \"log_loss\"\n",
    "            else:\n",
    "                loss_func = \"mean_squared_error\"\n",
    "\n",
    "        if isinstance(column, str):\n",
    "            if hasattr(learner, \"columns\"):\n",
    "                column = learner.columns.get_loc(column)\n",
    "\n",
    "        if infer_method == \"perm\":\n",
    "            if n_repeats is None:\n",
    "                n_repeats = 2000\n",
    "\n",
    "        self.learner = learner\n",
    "        self.remover = remover\n",
    "        self.column = column\n",
    "        self.loss_func = loss_func\n",
    "        self.infer_method = infer_method\n",
    "        self.n_repeats = n_repeats\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def infer(\n",
    "        self):\n",
    "        learner = self.learner\n",
    "        remover = self.remover\n",
    "        column = self.column\n",
    "        infer_method = self.infer_method\n",
    "        loss_func = self.loss_func\n",
    "        n_repeats = self.n_repeats\n",
    "        random_state = self.random_state\n",
    "        \n",
    "        if loss_func == \"log_loss\":\n",
    "            def log_loss(target, pred):\n",
    "                eps = np.finfo(pred.dtype).eps\n",
    "                pred = np.clip(pred, eps, 1 - eps)\n",
    "                loss = -xlogy(target, pred).sum(axis=1)\n",
    "                return loss\n",
    "            loss_func = log_loss\n",
    "            binarize = True\n",
    "            response_method = \"predict_proba\" \n",
    "\n",
    "        if loss_func == \"mean_squared_error\":\n",
    "            def mean_squared_error(target, pred):\n",
    "                loss = (target - pred)**2\n",
    "                return loss\n",
    "            loss_func = mean_squared_error\n",
    "            binarize = False\n",
    "            response_method = \"predict\"\n",
    "            \n",
    "        l_features = learner._features()\n",
    "        l_targets = learner._targets(binarize)\n",
    "        l_preds = learner._preds(response_method)\n",
    "        l_losses = [loss_func(l_target, l_pred)\n",
    "                   for l_target, l_pred in zip(l_targets, l_preds)]\n",
    "        \n",
    "        r_features = l_features\n",
    "        r_rvs = remover._rvs(\n",
    "            n_repeats = n_repeats,\n",
    "            random_state = random_state)\n",
    "        r_losses = []\n",
    "        \n",
    "        if infer_method == \"perm\":\n",
    "            def _r_loss_repeat(r_rv_repeat):\n",
    "                if hasattr(r_feature, \"iloc\"):\n",
    "                    r_feature.iloc[:, column] = r_rv_repeat\n",
    "                else:\n",
    "                    r_feature[:,column] = r_rv_repeat\n",
    "                r_pred_repeat = learner.predict(r_feature, split)\n",
    "                r_loss_repeat = loss_func(l_target, r_pred_repeat)\n",
    "                return r_loss_repeat\n",
    "            \n",
    "            null_values = []  \n",
    "            for split, (l_loss, l_target, r_feature, r_rv) in enumerate(\n",
    "                zip(l_losses, l_targets, r_features, r_rvs)):\n",
    "                r_loss = np.apply_along_axis(\n",
    "                    _r_loss_repeat,\n",
    "                    axis = 1,\n",
    "                    arr = r_rv)\n",
    "                null_value = (l_loss - r_loss).mean(axis = 1)\n",
    "                null_values.append(null_value)\n",
    "                r_losses.append(r_loss.mean(axis = 0))\n",
    "        else:\n",
    "            null_values = None\n",
    "            for split, (l_target, r_feature, r_rv) in enumerate(\n",
    "                zip(l_targets, r_features, r_rvs)):\n",
    "                if hasattr(r_feature, \"iloc\"):\n",
    "                    r_feature.iloc[:, column] = r_rv\n",
    "                else:\n",
    "                    r_feature[:,column] = r_rv\n",
    "                r_pred = learner.predict(r_feature, split)\n",
    "                r_loss = loss_func(l_target, r_pred)\n",
    "                r_losses.append(r_loss)\n",
    "        \n",
    "        self.learner_losses_ = l_losses\n",
    "        self.rival_losses_ = r_losses\n",
    "        self.null_values_ = null_values\n",
    "\n",
    "    def summarize(\n",
    "        self,\n",
    "        agg_method = None\n",
    "    ):\n",
    "        if agg_method is None:\n",
    "            summary = pd.DataFrame(\n",
    "                {\"estimate\": self._estimates(),\n",
    "                 \"std_error\": self._std_errors(),\n",
    "                 \"p_value\": self._p_values()}\n",
    "            )\n",
    "            summary.index.name = \"split\" \n",
    "        \n",
    "        return summary\n",
    "        \n",
    "\n",
    "    def _estimates(\n",
    "        self\n",
    "    ):\n",
    "        l_losses = self.learner_losses_\n",
    "        r_losses = self.rival_losses_\n",
    "        estimates = [l_loss.mean() - r_loss.mean()\n",
    "               for l_loss, r_loss in zip(l_losses, r_losses)]\n",
    "        return estimates\n",
    "\n",
    "    def _std_errors(\n",
    "        self\n",
    "    ):\n",
    "        infer_method = self.infer_method\n",
    "        if infer_method == \"perm\":\n",
    "            null_values = self.null_values_\n",
    "            std_errors = [null_value.std() \n",
    "                          for null_value in null_values]\n",
    "        else:\n",
    "            l_losses = self.learner_losses_\n",
    "            r_losses = self.rival_losses_\n",
    "            std_errors = [(l_loss - r_loss).std() / np.sqrt(len(l_loss)) \n",
    "                          for l_loss, r_loss in zip(l_losses, r_losses)]\n",
    "        return std_errors\n",
    "\n",
    "    def _p_values(\n",
    "        self\n",
    "    ):\n",
    "        infer_method = self.infer_method\n",
    "        if infer_method == \"perm\":\n",
    "            null_values = self.null_values_\n",
    "            p_values = [(null_value > 0).mean() \n",
    "                        for null_value in null_values]\n",
    "        else:\n",
    "            estimates = self._estimates()\n",
    "            std_errors = self._std_errors()\n",
    "            p_values = [scipy.stats.norm.cdf(estimate / std_error) \n",
    "                        for estimate, std_error in zip(estimates, std_errors)]\n",
    "        return p_values\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f889c144-8d8e-4945-bde0-89f8bf8b89bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RIT():\n",
    "    def __init__(\n",
    "        self, \n",
    "        learner,\n",
    "        rival,\n",
    "        infer_method = \"normal\",\n",
    "        loss_func = None,\n",
    "        n_repeats = None,\n",
    "        random_state = None\n",
    "    ):\n",
    "        if loss_func is None:\n",
    "            if is_classifier(learner.estimator):\n",
    "                loss_func = \"log_loss\"\n",
    "            else:\n",
    "                loss_func = \"mean_squared_error\"\n",
    "\n",
    "        if infer_method == \"perm\":\n",
    "            if n_repeats is None:\n",
    "                n_repeats = 2000\n",
    "\n",
    "        self.learner = learner\n",
    "        self.rival = rival\n",
    "        self.loss_func = loss_func\n",
    "        self.infer_method = infer_method\n",
    "        self.n_repeats = n_repeats\n",
    "        self.random_state = random_state\n",
    "\n",
    "\n",
    "    def infer(\n",
    "        self):\n",
    "        learner = self.learner\n",
    "        rival = self.rival\n",
    "        infer_method = self.infer_method\n",
    "        loss_func = self.loss_func\n",
    "        n_repeats = self.n_repeats\n",
    "        random_state = self.random_state\n",
    "        \n",
    "        if loss_func == \"log_loss\":\n",
    "            def log_loss(target, pred):\n",
    "                eps = np.finfo(pred.dtype).eps\n",
    "                pred = np.clip(pred, eps, 1 - eps)\n",
    "                loss = -xlogy(target, pred).sum(axis=1)\n",
    "                return loss\n",
    "            loss_func = log_loss\n",
    "            binarize = True\n",
    "            response_method = \"predict_proba\" \n",
    "\n",
    "        if loss_func == \"mean_squared_error\":\n",
    "            def mean_squared_error(target, pred):\n",
    "                loss = (target - pred)**2\n",
    "                return loss\n",
    "            loss_func = mean_squared_error\n",
    "            binarize = False\n",
    "            response_method = \"predict\"\n",
    "\n",
    "        l_targets = learner._targets(binarize)\n",
    "        l_preds = learner._preds(response_method)\n",
    "        l_losses = [loss_func(l_target, l_pred)\n",
    "                   for l_target, l_pred in zip(l_targets, l_preds)]\n",
    "        \n",
    "        r_targets = rival._targets(binarize)\n",
    "        r_preds = rival._preds(response_method)\n",
    "        r_losses = [loss_func(r_target, r_pred)\n",
    "                   for r_target, r_pred in zip(r_targets, r_preds)]\n",
    "        \n",
    "        if infer_method == \"perm\":\n",
    "            null_values = [] \n",
    "            rng = np.random.default_rng(random_state)\n",
    "            for l_loss, r_loss in zip(l_losses, r_losses):\n",
    "                estimate = l_loss.mean() - r_loss.mean()\n",
    "                paired_loss = np.column_stack([l_loss, r_loss])\n",
    "                null_value = np.array([\n",
    "                    estimate - np.diff(\n",
    "                        rng.permuted(\n",
    "                            paired_loss, \n",
    "                            axis = 1).mean(\n",
    "                            axis = 0)).item() \n",
    "                    for repeat in range(n_repeats)])\n",
    "                null_values.append(null_value)\n",
    "        else:\n",
    "            null_values = None\n",
    "        \n",
    "        self.learner_losses_ = l_losses\n",
    "        self.rival_losses_ = r_losses\n",
    "        self.null_values_ = null_values\n",
    "\n",
    "    def summarize(\n",
    "        self,\n",
    "        agg_method = None\n",
    "    ):\n",
    "        if agg_method is None:\n",
    "            summary = pd.DataFrame(\n",
    "                {\"estimate\": self._estimates(),\n",
    "                 \"std_error\": self._std_errors(),\n",
    "                 \"p_value\": self._p_values()}\n",
    "            )\n",
    "            summary.index.name = \"split\" \n",
    "        \n",
    "        return summary\n",
    "\n",
    "\n",
    "    def _estimates(\n",
    "        self\n",
    "    ):\n",
    "        l_losses = self.learner_losses_\n",
    "        r_losses = self.rival_losses_\n",
    "        estimates = [l_loss.mean()  - r_loss.mean()\n",
    "               for l_loss, r_loss in zip(l_losses, r_losses)]\n",
    "        return estimates\n",
    "\n",
    "    def _std_errors(\n",
    "        self\n",
    "    ):\n",
    "        infer_method = self.infer_method\n",
    "        if infer_method == \"perm\":\n",
    "            null_values = self.null_values_\n",
    "            std_errors = [null_value.std() \n",
    "                          for null_value in null_values]\n",
    "        else:\n",
    "            l_losses = self.learner_losses_\n",
    "            r_losses = self.rival_losses_\n",
    "            std_errors = [(l_loss - r_loss).std() / np.sqrt(len(l_loss)) \n",
    "                          for l_loss, r_loss in zip(l_losses, r_losses)]\n",
    "        return std_errors\n",
    "\n",
    "    def _p_values(\n",
    "        self\n",
    "    ):\n",
    "        infer_method = self.infer_method\n",
    "        if infer_method == \"perm\":\n",
    "            null_values = self.null_values_\n",
    "            p_values = [(null_value > 0).mean() \n",
    "                        for null_value in null_values]\n",
    "        else:\n",
    "            estimates = self._estimates()\n",
    "            std_errors = self._std_errors()\n",
    "            p_values = [scipy.stats.norm.cdf(estimate / std_error) \n",
    "                        for estimate, std_error in zip(estimates, std_errors)]\n",
    "        return p_values\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a43bbdcd-f7af-4094-ba90-3ef90af877d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold, RepeatedKFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "splitter = RepeatedKFold(\n",
    "    n_splits = 2, \n",
    "    n_repeats = 3, \n",
    "    random_state = 0)\n",
    "learner = CrossEstimator(\n",
    "    GridSearchCV(\n",
    "            estimator = RandomForestRegressor(), \n",
    "            param_grid = {\n",
    "                \"max_features\": [3, 6, 9]}, \n",
    "            cv = 4),\n",
    "    cv = splitter)\n",
    "rival = CrossEstimator(\n",
    "    GridSearchCV(\n",
    "            estimator = RandomForestRegressor(), \n",
    "            param_grid = {\n",
    "                \"max_features\": [3, 6, 9]}, \n",
    "            cv = 4),\n",
    "    cv = splitter)\n",
    "remover = CrossEstimator(\n",
    "    GridSearchCV(\n",
    "            estimator = RandomForestRegressor(), \n",
    "            param_grid = {\n",
    "                \"max_features\": [3, 6, 9]}, \n",
    "            cv = 4),\n",
    "    cv = splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f99a14c-7737-4fc2-8e13-835fe6286623",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, r2 = gen_xy(\n",
    "        model = \"linear\",\n",
    "        iv_corr = .8,\n",
    "        n_obs= 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27d1ca2e-8193-4153-a29a-f4245d2959a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "column = 1\n",
    "_ = learner.fit(X, y)\n",
    "_ = rival.fit(np.delete(X, column, axis = 1), y)\n",
    "_ = remover.fit(\n",
    "    np.delete(X, column, axis = 1), \n",
    "    X[:,column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0c594f5-821d-45ba-812d-e4a4da4f0aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimate</th>\n",
       "      <th>std_error</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002556</td>\n",
       "      <td>0.011504</td>\n",
       "      <td>0.5920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.011015</td>\n",
       "      <td>0.010345</td>\n",
       "      <td>0.1465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.027820</td>\n",
       "      <td>0.010467</td>\n",
       "      <td>0.0045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.003819</td>\n",
       "      <td>0.010363</td>\n",
       "      <td>0.3560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.015133</td>\n",
       "      <td>0.010132</td>\n",
       "      <td>0.0725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.005350</td>\n",
       "      <td>0.008492</td>\n",
       "      <td>0.2615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       estimate  std_error  p_value\n",
       "split                              \n",
       "0      0.002556   0.011504   0.5920\n",
       "1     -0.011015   0.010345   0.1465\n",
       "2     -0.027820   0.010467   0.0045\n",
       "3     -0.003819   0.010363   0.3560\n",
       "4     -0.015133   0.010132   0.0725\n",
       "5     -0.005350   0.008492   0.2615"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rit = RIT(\n",
    "    learner, \n",
    "    rival, \n",
    "    infer_method = \"perm\")\n",
    "_ = rit.infer()\n",
    "rit.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f0890e1-1e2b-43b4-9d1e-8a95f7d74f0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimate</th>\n",
       "      <th>std_error</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002556</td>\n",
       "      <td>0.011557</td>\n",
       "      <td>0.587513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.011015</td>\n",
       "      <td>0.010451</td>\n",
       "      <td>0.145949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.027820</td>\n",
       "      <td>0.010005</td>\n",
       "      <td>0.002712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.003819</td>\n",
       "      <td>0.010288</td>\n",
       "      <td>0.355246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.015133</td>\n",
       "      <td>0.010017</td>\n",
       "      <td>0.065442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.005350</td>\n",
       "      <td>0.008652</td>\n",
       "      <td>0.268161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       estimate  std_error   p_value\n",
       "split                               \n",
       "0      0.002556   0.011557  0.587513\n",
       "1     -0.011015   0.010451  0.145949\n",
       "2     -0.027820   0.010005  0.002712\n",
       "3     -0.003819   0.010288  0.355246\n",
       "4     -0.015133   0.010017  0.065442\n",
       "5     -0.005350   0.008652  0.268161"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rit = RIT(\n",
    "    learner, \n",
    "    rival, \n",
    "    infer_method = \"normal\")\n",
    "_ = rit.infer()\n",
    "rit.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45ee92ca-ad5c-4a9b-9413-a32b9565948d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimate</th>\n",
       "      <th>std_error</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.020521</td>\n",
       "      <td>0.007544</td>\n",
       "      <td>0.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.011597</td>\n",
       "      <td>0.008462</td>\n",
       "      <td>0.0905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.013881</td>\n",
       "      <td>0.006190</td>\n",
       "      <td>0.0115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.017490</td>\n",
       "      <td>0.007885</td>\n",
       "      <td>0.0130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.025849</td>\n",
       "      <td>0.009572</td>\n",
       "      <td>0.0020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.020276</td>\n",
       "      <td>0.008542</td>\n",
       "      <td>0.0080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       estimate  std_error  p_value\n",
       "split                              \n",
       "0     -0.020521   0.007544   0.0015\n",
       "1     -0.011597   0.008462   0.0905\n",
       "2     -0.013881   0.006190   0.0115\n",
       "3     -0.017490   0.007885   0.0130\n",
       "4     -0.025849   0.009572   0.0020\n",
       "5     -0.020276   0.008542   0.0080"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cit = CIT(\n",
    "    learner, \n",
    "    remover, \n",
    "    column,\n",
    "    infer_method = \"perm\")\n",
    "_ = cit.infer()\n",
    "cit.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd622fb4-ef9f-4d3b-954a-0d20ec9856fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimate</th>\n",
       "      <th>std_error</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.013882</td>\n",
       "      <td>0.008926</td>\n",
       "      <td>0.059945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.020936</td>\n",
       "      <td>0.010826</td>\n",
       "      <td>0.026559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001111</td>\n",
       "      <td>0.008767</td>\n",
       "      <td>0.550424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.018776</td>\n",
       "      <td>0.011302</td>\n",
       "      <td>0.048328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.024897</td>\n",
       "      <td>0.013682</td>\n",
       "      <td>0.034403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.028159</td>\n",
       "      <td>0.009320</td>\n",
       "      <td>0.001258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       estimate  std_error   p_value\n",
       "split                               \n",
       "0     -0.013882   0.008926  0.059945\n",
       "1     -0.020936   0.010826  0.026559\n",
       "2      0.001111   0.008767  0.550424\n",
       "3     -0.018776   0.011302  0.048328\n",
       "4     -0.024897   0.013682  0.034403\n",
       "5     -0.028159   0.009320  0.001258"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cit = CIT(\n",
    "    learner, \n",
    "    remover, \n",
    "    column,\n",
    "    infer_method = \"normal\")\n",
    "_ = cit.infer()\n",
    "cit.summarize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
