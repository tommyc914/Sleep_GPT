{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59662b87-f10b-4fd6-8460-83f8b2bb53cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import clone\n",
    "from sklearn import model_selection\n",
    "from sklearn.base import is_classifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import get_scorer, check_scoring\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from scipy.special import xlogy\n",
    "from scipy.stats import hmean, gmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "824384cd-7b30-41d7-bd01-3d7ede661674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_xy(\n",
    "    model,\n",
    "    iv_corr,\n",
    "    n_obs):\n",
    "    n_ivs = 10\n",
    "    mean = np.zeros((n_ivs,))\n",
    "    cov = np.block([[(iv_corr * np.ones((n_ivs - 3, n_ivs - 3)) + \n",
    "         (1 - iv_corr) * np.eye(n_ivs - 3)), np.zeros((7, 3))],\n",
    "                    [np.zeros((3, 7)), np.eye(3)]])\n",
    "    x = np.random.multivariate_normal(\n",
    "      mean = mean, \n",
    "      cov = cov, \n",
    "      size = n_obs)\n",
    "    if model == \"linear\":\n",
    "        coef = np.array([.1, .2, .3, .4]).reshape(4, -1)\n",
    "        cov_signal = cov[0:4, 0:4]\n",
    "        error_var = 1 - (coef.T @ cov_signal @ coef).item()\n",
    "        x_signal = x[:,0:4]\n",
    "    else:\n",
    "        coef = np.array([.3, .3, .3, .4]).reshape(4, -1)\n",
    "        sd_quad = np.sqrt(2)\n",
    "        sd_prod = np.sqrt(1 + iv_corr**2)\n",
    "        a = (2 * (iv_corr**2)) / (sd_quad * sd_quad)\n",
    "        b = (2 * (iv_corr**2)) / (sd_quad * sd_prod)\n",
    "        cov_signal = np.array(\n",
    "            [[ 1.  ,  0.  , 0.  ,  0.  ],\n",
    "             [ 0.  ,  1.  ,  a,  b],\n",
    "             [0.  ,  a,  1.  ,  b],\n",
    "             [ 0.  ,  b,  b,  1.  ]])\n",
    "        error_var = 1 - (coef.T @ cov_signal @ coef).item()\n",
    "        x_signal = np.concatenate(\n",
    "            (x[:,0:1], \n",
    "             (x[:,0:1]**2)  / sd_quad, \n",
    "             (x[:,1:2]**2) / sd_quad,\n",
    "             (x[:,2:3] * x[:,3:4]) / sd_prod), \n",
    "            axis = 1)\n",
    "    error = np.random.normal(\n",
    "      loc = 0.0, \n",
    "      scale = np.sqrt(error_var), \n",
    "      size = (n_obs, ))\n",
    "    y = (x_signal @ coef).reshape(-1,) + error\n",
    "    r2 = 1 - error_var\n",
    "    return x, y, r2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c096675-d58c-4854-9c74-01eb271a49ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Crosser():\n",
    "    def __init__(\n",
    "        self,\n",
    "        estimator,\n",
    "        cv\n",
    "    ):\n",
    "        cv, n_splits, n_repeats, n_folds = self._check_cv(cv)\n",
    "        self.estimator = estimator\n",
    "        self.cv = cv\n",
    "        self.n_splits = n_splits\n",
    "        self.n_repeats = n_repeats\n",
    "        self.n_folds = n_folds\n",
    "\n",
    "    def fit(\n",
    "        self, \n",
    "        X, \n",
    "        y\n",
    "    ):\n",
    "        cv = self.cv\n",
    "        cv_indexes = []\n",
    "        estimators = []\n",
    "        for train_index, test_index in cv.split(X):     \n",
    "            estimator = clone(self.estimator)\n",
    "            if hasattr(X, \"iloc\") and hasattr(y, \"iloc\"):\n",
    "                _ = estimator.fit(\n",
    "                    X.iloc[train_index,], \n",
    "                    y.iloc[train_index])\n",
    "            else:\n",
    "                _ = estimator.fit(\n",
    "                    X[train_index,], \n",
    "                    y[train_index])\n",
    "            estimator = estimator\n",
    "            estimators.append(estimator)               \n",
    "            cv_indexes.append((train_index, test_index))\n",
    "        self.X_, self.y_ = X.copy(), y.copy()\n",
    "        self.estimators_ = estimators\n",
    "        self.cv_indexes_ = cv_indexes\n",
    "        if is_classifier(self.estimator):\n",
    "            label_binarizer = LabelBinarizer()\n",
    "            _ = label_binarizer.fit(y)\n",
    "            self.label_binarizer_ = label_binarizer\n",
    "        return self\n",
    "\n",
    "    def predict(\n",
    "        self, \n",
    "        X,\n",
    "        *,\n",
    "        split = None\n",
    "    ):\n",
    "        if split is None:\n",
    "            preds = np.array(\n",
    "                [estimator.predict(X) \n",
    "                 for estimator in self.estimators_])\n",
    "            if is_classifier(self.estimator):\n",
    "                pred = np.apply_along_axis(\n",
    "                    lambda x: np.argmax(np.bincount(x)),\n",
    "                    axis = 0,\n",
    "                    arr = preds)\n",
    "            else:\n",
    "                pred = preds.mean(axis = 0)\n",
    "        else:\n",
    "            pred = self.estimators_[split].predict(X)\n",
    "        return pred\n",
    "\n",
    "    def predict_proba(\n",
    "        self, \n",
    "        X,\n",
    "        *,\n",
    "        split = None\n",
    "    ):\n",
    "        if split is None:\n",
    "            preds = np.array(\n",
    "                [estimator.predict_proba(X)\n",
    "                 for estimator in self.estimators_])\n",
    "            pred = preds.mean(axis = 0)\n",
    "        else:\n",
    "            pred = self.estimators_[split].predict_proba(X)\n",
    "        return pred\n",
    "\n",
    "    def predict_log_proba(\n",
    "        self, \n",
    "        X,\n",
    "        *,\n",
    "        split = None\n",
    "    ):\n",
    "        if split is None:\n",
    "            preds = np.array(\n",
    "                [estimator.predict_log_proba(X)\n",
    "                 for estimator in self.estimators_])\n",
    "            pred = preds.mean(axis = 0)\n",
    "        else:\n",
    "            pred = self.estimators_[split].predict_log_proba(X)\n",
    "        return pred\n",
    "            \n",
    "    def decision_function(\n",
    "        self, \n",
    "        X,\n",
    "        *,\n",
    "        split = None\n",
    "    ):\n",
    "        if split is None:\n",
    "            preds = np.array(\n",
    "                [estimator.decision_function(X) \n",
    "                 for estimator in self.estimators_])\n",
    "            pred = preds.mean(axis = 0)\n",
    "        else:\n",
    "            pred = self.estimators_[split].decision_function(X)\n",
    "        return pred\n",
    "            \n",
    "    \n",
    "    def sample(\n",
    "        self,\n",
    "        X,\n",
    "        *,\n",
    "        split = None,\n",
    "        n_samples = None, \n",
    "        random_state = None\n",
    "    ):\n",
    "        rng = np.random.default_rng(random_state)\n",
    "        if is_classifier(self.estimator):\n",
    "            pred = self.predict_proba(\n",
    "                X, \n",
    "                split = split)\n",
    "            if n_samples is None:            \n",
    "                rv = rng.multinomial(1, pred)\n",
    "                rv = self.label_binarizer_.inverse_transform(rv)\n",
    "            else:\n",
    "                rv = rng.multinomial(\n",
    "                    1, pred, (n_samples, len(pred)))\n",
    "                rv = np.array(\n",
    "                    [self.label_binarizer_.inverse_transform(rv_i) \n",
    "                     for rv_i in rv])\n",
    "        else:\n",
    "            if split is None:\n",
    "                targets = self._targets()\n",
    "                preds = self._preds()\n",
    "                residual = np.concatenate(\n",
    "                    [target - pred \n",
    "                     for target, pred in zip(targets, preds)])\n",
    "            else:\n",
    "                train_index, test_index = self.cv_indexes_[split]\n",
    "                if hasattr(self.X_, \"iloc\") and hasattr(self.y_, \"iloc\"):\n",
    "                    feature = self.X_.iloc[test_index, :]\n",
    "                    target = self.y_.iloc[test_index]\n",
    "                else:\n",
    "                    feature = self.X_[test_index, :]\n",
    "                    target = self.y_[test_index]\n",
    "                pred = self.predict(\n",
    "                    feature, \n",
    "                    split = split)     \n",
    "                residual = target - pred\n",
    "            pred = self.predict(\n",
    "                X, \n",
    "                split = split)\n",
    "            if len(pred) > len(residual):\n",
    "                replace = True\n",
    "            else:\n",
    "                replace = False\n",
    "            if n_samples is None:\n",
    "                rv = pred + rng.choice(residual, len(pred), replace)\n",
    "            else:\n",
    "                rv = pred + np.array(\n",
    "                    [rng.choice(residual, len(pred), replace) \n",
    "                     for repeat in range(n_samples)])\n",
    "        return rv\n",
    "\n",
    "    \n",
    "    def _features(\n",
    "        self\n",
    "    ):\n",
    "        features = []\n",
    "        for train_index, test_index in self.cv_indexes_:\n",
    "            if hasattr(self.X_, \"iloc\"):\n",
    "                feature = self.X_.iloc[test_index, :]\n",
    "            else:\n",
    "                feature = self.X_[test_index, :]\n",
    "            features.append(feature)\n",
    "        return features\n",
    "    \n",
    "    def _targets(\n",
    "        self,\n",
    "        binarize = None\n",
    "    ):\n",
    "        targets = []\n",
    "        for train_index, test_index in self.cv_indexes_:\n",
    "            if hasattr(self.y_, \"iloc\"):\n",
    "                target = self.y_.iloc[test_index]\n",
    "            else:\n",
    "                target = self.y_[test_index]\n",
    "            if is_classifier(self.estimator):\n",
    "                if binarize is True:\n",
    "                    target = self.label_binarizer_.transform(target)\n",
    "                    if target.shape[1] == 1:\n",
    "                        target = np.append(1 - target, target, axis=1)\n",
    "            targets.append(target)\n",
    "        return targets\n",
    "\n",
    "    def _preds(\n",
    "        self,\n",
    "        response_method = \"predict\"\n",
    "    ):\n",
    "        preds = []\n",
    "        for split, (train_index, test_index) in enumerate(self.cv_indexes_):\n",
    "            predict_func = getattr(self, response_method)\n",
    "            if hasattr(self.X_, \"iloc\"):\n",
    "                feature = self.X_.iloc[test_index, :]\n",
    "            else:\n",
    "                feature = self.X_[test_index, :]\n",
    "            pred = predict_func(feature, split = split)\n",
    "            preds.append(pred)\n",
    "        return preds\n",
    "\n",
    "    def _rvs(\n",
    "        self,\n",
    "        n_samples = None,\n",
    "        random_state = None\n",
    "    ):\n",
    "        rvs = []\n",
    "        for split, (train_index, test_index) in enumerate(self.cv_indexes_):\n",
    "            if hasattr(self.X_, \"iloc\"):\n",
    "                feature = self.X_.iloc[test_index, :]\n",
    "            else:\n",
    "                feature = self.X_[test_index, :]\n",
    "            rv = self.sample(\n",
    "                feature, \n",
    "                split = split, \n",
    "                n_samples = n_samples,\n",
    "                random_state = random_state)\n",
    "            rvs.append(rv)\n",
    "        return rvs\n",
    "\n",
    "\n",
    "    def _check_cv(\n",
    "        self,\n",
    "        cv\n",
    "    ):\n",
    "        kf_cvs = {\"KFold\", \"RepeatedKFold\", \n",
    "                  \"StratifiedKFold\", \"RepeatedStratifiedKFold\"}\n",
    "        ss_cvs = {\"ShuffleSplit\", \"StratifiedShuffleSplit\"}\n",
    "        allowed_cvs = set.union(ss_cvs, kf_cvs)\n",
    "        if isinstance(\n",
    "            cv,\n",
    "            tuple(getattr(model_selection, allowed_cv) \n",
    "                  for allowed_cv in allowed_cvs)\n",
    "        ):\n",
    "            n_splits = cv.get_n_splits()\n",
    "            if isinstance(\n",
    "                cv, \n",
    "                tuple(getattr(model_selection, kf_cv) \n",
    "                      for kf_cv in kf_cvs)):\n",
    "                if hasattr(cv, \"n_repeats\"):\n",
    "                    n_repeats = cv.n_repeats\n",
    "                else:\n",
    "                    n_repeats = 1\n",
    "            else:\n",
    "                n_repeats = cv.get_n_splits()\n",
    "            n_folds = n_splits // n_repeats\n",
    "        else:\n",
    "            raise ValueError(\"Support cross-validator types are {}\".format(allowed_cvs))\n",
    "        return cv, n_splits, n_repeats, n_folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56ea635a-ae68-49a2-9d6c-6d18828bfb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseInferer():\n",
    "    def __init__(\n",
    "        self, \n",
    "        learner,\n",
    "        remover,\n",
    "        algorithm,\n",
    "        *,\n",
    "        loss_func = None,\n",
    "        infer_type = None,\n",
    "        n_samples = None,\n",
    "        n_permutations = None,\n",
    "        double_split = None,\n",
    "        perturb_size = None,\n",
    "        random_state = None,\n",
    "        removed_column = None):\n",
    "        if loss_func is None:\n",
    "            if is_classifier(learner.estimator):\n",
    "                loss_func = \"log_loss\"\n",
    "            else:\n",
    "                loss_func = \"mean_squared_error\"\n",
    "\n",
    "        if loss_func == \"log_loss\":\n",
    "            def log_loss(target, pred):\n",
    "                eps = np.finfo(pred.dtype).eps\n",
    "                pred = np.clip(pred, eps, 1 - eps)\n",
    "                loss = -xlogy(target, pred).sum(axis=1)\n",
    "                return loss\n",
    "            loss_func = log_loss\n",
    "            binarize = True\n",
    "            response_method = \"predict_proba\" \n",
    "\n",
    "        if loss_func == \"zero_one_loss\":\n",
    "            def zero_one_loss(target, pred):\n",
    "                loss = 1 * (target == pred)\n",
    "                return loss\n",
    "            loss_func = zero_one_loss\n",
    "            binarize = False\n",
    "            response_method = \"predict\" \n",
    "        \n",
    "        if loss_func == \"mean_squared_error\":\n",
    "            def mean_squared_error(target, pred):\n",
    "                loss = (target - pred)**2\n",
    "                return loss\n",
    "            loss_func = mean_squared_error\n",
    "            binarize = False\n",
    "            response_method = \"predict\"\n",
    "        \n",
    "        if loss_func == \"mean_absolute_error\":\n",
    "            def mean_absolute_error(target, pred):\n",
    "                loss = np.abs(target - pred)\n",
    "                return loss\n",
    "            loss_func = mean_absolute_error\n",
    "            binarize = False\n",
    "            response_method = \"predict\"\n",
    "\n",
    "        self.learner = learner\n",
    "        self.remover = remover\n",
    "        self.algorithm = algorithm\n",
    "        self.loss_func = loss_func\n",
    "        self.infer_type = infer_type\n",
    "        self.n_samples = n_samples\n",
    "        self.n_permutations = n_permutations\n",
    "        self.double_split = double_split\n",
    "        self.perturb_size = perturb_size\n",
    "        self.random_state = random_state\n",
    "        self.removed_column = removed_column\n",
    "        self.binarize = binarize\n",
    "        self.response_method = response_method\n",
    "\n",
    "    def summarize(\n",
    "        self,\n",
    "        *,\n",
    "        agg_method = None,\n",
    "        cross_fit = None\n",
    "    ):\n",
    "        if agg_method is None:\n",
    "            summary = pd.DataFrame(\n",
    "                {\"estimate\": self._estimates(),\n",
    "                 \"std_error\": self._std_errors(),\n",
    "                 \"p_value\": self._p_values()}\n",
    "            )\n",
    "            summary.index.name = \"split\" \n",
    "            \n",
    "        elif agg_method == \"gmean\":\n",
    "            \n",
    "            summary = pd.DataFrame(\n",
    "                {\"estimate\": np.mean(self._estimates()),\n",
    "                 \"std_error\": np.mean(self._std_errors()),\n",
    "                 \"p_value\": np.minimum(np.e * gmean(self._p_values(), 0), 1.)},\n",
    "                index = [0]\n",
    "            )\n",
    "            \n",
    "        elif agg_method == \"median\":\n",
    "            \n",
    "            summary = pd.DataFrame(\n",
    "                {\"estimate\": np.mean(self._estimates()),\n",
    "                 \"std_error\": np.mean(self._std_errors()),\n",
    "                 \"p_value\": np.minimum(2*np.median(self._p_values(), 0), 1.)},\n",
    "                index = [0]\n",
    "            )\n",
    "            \n",
    "        elif agg_method == \"q1\": \n",
    "                \n",
    "            summary = pd.DataFrame(\n",
    "                {\"estimate\": np.mean(self._estimates()),\n",
    "                \"std_error\": np.mean(self._std_errors()),\n",
    "                \"p_value\": np.minimum(len(self._p_values()) / 2.*np.partition(self._p_values(), 1)[1], 1.)},\n",
    "                index = [0]\n",
    "            )\n",
    "                \n",
    "        elif agg_method == \"min\":\n",
    "                \n",
    "            summary = pd.DataFrame(\n",
    "                {\"estimate\": np.mean(self._estimates()),\n",
    "                \"std_error\": np.mean(self._std_errors()),\n",
    "                \"p_value\": np.minimum(len(self._p_values())*np.min(self._p_values(), 0), 1.)},\n",
    "                index = [0]\n",
    "            )\n",
    "                \n",
    "        elif agg_method == \"hmean\":    \n",
    "                \n",
    "            summary = pd.DataFrame(\n",
    "                {\"estimate\": np.mean(self._estimates()),\n",
    "                \"std_error\": np.mean(self._std_errors()),\n",
    "                \"p_value\": np.minimum(np.e * np.log(len(self._p_values())) * hmean(self._p_values(), 0), 1.)},\n",
    "                index = [0]\n",
    "            )\n",
    "                \n",
    "        elif agg_method == \"hommel\":\n",
    "                \n",
    "            const = np.sum(1. / (np.arange(len(self._p_values())) + 1.))\n",
    "            order_const = const * (len(self._p_values()) / (np.arange(len(self._p_values())) + 1.))\n",
    "            \n",
    "            summary = pd.DataFrame(\n",
    "                {\"estimate\": np.mean(self._estimates()),\n",
    "                \"std_error\": np.mean(self._std_errors()),\n",
    "                \"p_value\": np.minimum(np.min(np.sort(self._p_values()) * order_const), 1.)},\n",
    "                index = [0]\n",
    "            )\n",
    "        \n",
    "        elif agg_method == \"cauchy\":\n",
    "            \n",
    "            t0 =np.mean(np.tan((.5 - np.array(self._p_values()))*np.pi))\n",
    "                  \n",
    "            summary = pd.DataFrame(\n",
    "                {\"estimate\": np.mean(self._estimates()),\n",
    "                \"std_error\": np.mean(self._std_errors()),\n",
    "                \"p_value\": np.minimum(.5 - np.arctan(t0) / np.pi, 1.)},\n",
    "                index = [0]\n",
    "            )\n",
    "        \n",
    "        \n",
    "        return summary\n",
    "        \n",
    "\n",
    "    def _estimates(\n",
    "        self\n",
    "    ):\n",
    "        l_losses = self.learner_losses_\n",
    "        r_losses = self.removed_losses_\n",
    "        estimates = [l_loss.mean() - r_loss.mean()\n",
    "               for l_loss, r_loss in zip(l_losses, r_losses)]\n",
    "        return estimates\n",
    "\n",
    "    def _std_errors(\n",
    "        self\n",
    "    ):\n",
    "        infer_type = self.infer_type\n",
    "        if infer_type == \"permutation\" or infer_type == \"randomization\":\n",
    "            null_values = self.null_values_\n",
    "            std_errors = [null_value.std() \n",
    "                          for null_value in null_values]\n",
    "        else:\n",
    "            l_losses = self.learner_losses_\n",
    "            r_losses = self.removed_losses_\n",
    "            std_errors = [(l_loss - r_loss).std() / np.sqrt(len(l_loss)) \n",
    "                          for l_loss, r_loss in zip(l_losses, r_losses)]\n",
    "        return std_errors\n",
    "\n",
    "    def _p_values(\n",
    "        self\n",
    "    ):\n",
    "        infer_type = self.infer_type\n",
    "        if infer_type == \"permutation\" or infer_type == \"randomization\":\n",
    "            null_values = self.null_values_\n",
    "            p_values = [(null_value > 0).mean() \n",
    "                        for null_value in null_values]\n",
    "        else:\n",
    "            estimates = self._estimates()\n",
    "            std_errors = self._std_errors()\n",
    "            p_values = [scipy.stats.norm.cdf(estimate / std_error) \n",
    "                        for estimate, std_error in zip(estimates, std_errors)]\n",
    "        return p_values\n",
    "\n",
    "    def _removed_column(\n",
    "        self,\n",
    "        learner,\n",
    "        remover\n",
    "    ):\n",
    "        cols = np.arange(learner.X_.shape[1])\n",
    "        if hasattr(learner.X_, \"iloc\") and hasattr(remover.y_, \"iloc\"):\n",
    "            X, y = learner.X_.values, remover.y_.values\n",
    "        else:\n",
    "            X, y = learner.X_, remover.y_\n",
    "        for col in cols:\n",
    "            tester = np.array_equal(y, X[:,col])\n",
    "            if tester:\n",
    "                removed_column = col\n",
    "                break\n",
    "        return removed_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "110a1bfb-8cf0-4b50-a920-3ac7d02b0130",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIT(BaseInferer):\n",
    "    def infer(\n",
    "        self\n",
    "    ):\n",
    "        learner = self.learner\n",
    "        remover = self.remover\n",
    "        algorithm = self.algorithm\n",
    "        loss_func = self.loss_func\n",
    "        infer_type = self.infer_type\n",
    "        n_samples = self.n_samples\n",
    "        n_permutations = self.n_permutations\n",
    "        random_state = self.random_state\n",
    "        removed_column = self.removed_column\n",
    "        binarize = self.binarize\n",
    "        response_method = self.response_method\n",
    "        \n",
    "        l_features = learner._features()\n",
    "        l_targets = learner._targets(binarize)\n",
    "        l_preds = learner._preds(response_method)\n",
    "        l_losses = [loss_func(l_target, l_pred)\n",
    "                   for l_target, l_pred in zip(l_targets, l_preds)]\n",
    "        \n",
    "        r_features = l_features\n",
    "        r_rvs = remover._rvs(\n",
    "            n_samples = n_samples,\n",
    "            random_state = random_state)\n",
    "        r_losses = []\n",
    "\n",
    "        def _r_loss_repeat(r_rv_repeat):\n",
    "            if hasattr(r_feature, \"iloc\"):\n",
    "                r_feature.iloc[:, removed_column] = r_rv_repeat\n",
    "            else:\n",
    "                r_feature[:, removed_column] = r_rv_repeat\n",
    "            r_pred_repeat = learner.predict(\n",
    "                r_feature, \n",
    "                split = split)\n",
    "            r_loss_repeat = loss_func(l_target, r_pred_repeat)\n",
    "            return r_loss_repeat\n",
    "        \n",
    "        for split, (l_loss, l_target, r_feature, r_rv) in enumerate(\n",
    "            zip(l_losses, l_targets, r_features, r_rvs)):\n",
    "            r_loss = np.apply_along_axis(\n",
    "                _r_loss_repeat,\n",
    "                axis = 1,\n",
    "                arr = r_rv)\n",
    "            r_losses.append(r_loss)\n",
    "        \n",
    "        if infer_type == \"randomization\":\n",
    "            null_values = []  \n",
    "            for split, (l_loss, r_loss) in enumerate(\n",
    "                zip(l_losses, r_losses)):\n",
    "                null_value = (l_loss - r_loss).mean(axis = 1)\n",
    "                null_values.append(null_value)\n",
    "                r_loss = r_loss.mean(axis = 0)\n",
    "                r_losses[split] = r_loss\n",
    "        else:\n",
    "            for split, (l_loss, r_loss) in enumerate(\n",
    "                zip(l_losses, r_losses)):\n",
    "                r_loss = r_loss.mean(axis = 0)\n",
    "                r_losses[split] = r_loss\n",
    "            \n",
    "            if infer_type == \"permutation\":\n",
    "                null_values = [] \n",
    "                rng = np.random.default_rng(random_state)\n",
    "                for split, (l_loss, r_loss) in enumerate(\n",
    "                    zip(l_losses, r_losses)):\n",
    "                    estimate = l_loss.mean() - r_loss.mean()\n",
    "                    paired_loss = np.column_stack([l_loss, r_loss])\n",
    "                    null_value = np.array([\n",
    "                        estimate - np.diff(\n",
    "                            rng.permuted(\n",
    "                                paired_loss, \n",
    "                                axis = 1).mean(\n",
    "                                axis = 0)).item() \n",
    "                        for permutation in range(n_permutations)])\n",
    "                    null_values.append(null_value)\n",
    "            else:\n",
    "                null_values = None\n",
    "\n",
    "        \n",
    "        self.learner_losses_ = l_losses\n",
    "        self.removed_losses_ = r_losses\n",
    "        self.null_values_ = null_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85e37f00-3d92-4115-b0d8-2db04a7c0cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RIT(BaseInferer):\n",
    "    def infer(\n",
    "        self\n",
    "    ):\n",
    "        learner = self.learner\n",
    "        remover = self.remover\n",
    "        algorithm = self.algorithm\n",
    "        loss_func = self.loss_func\n",
    "        infer_type = self.infer_type\n",
    "        n_permutations = self.n_permutations\n",
    "        double_split = self.double_split\n",
    "        perturb_size = self.perturb_size\n",
    "        random_state = self.random_state\n",
    "        binarize = self.binarize\n",
    "        response_method = self.response_method\n",
    "\n",
    "        l_targets = learner._targets(binarize)\n",
    "        l_preds = learner._preds(response_method)\n",
    "        l_losses = [loss_func(l_target, l_pred)\n",
    "                   for l_target, l_pred in zip(l_targets, l_preds)]\n",
    "        \n",
    "        r_targets = remover._targets(binarize)\n",
    "        r_preds = remover._preds(response_method)\n",
    "        r_losses = [loss_func(r_target, r_pred)\n",
    "                   for r_target, r_pred in zip(r_targets, r_preds)]\n",
    "\n",
    "        if perturb_size is not None:\n",
    "            rng = np.random.default_rng(random_state)\n",
    "            r_losses = [r_loss + rng.normal(\n",
    "                scale = perturb_size, \n",
    "                size = len(r_loss)) for r_loss in r_losses]\n",
    "            \n",
    "        if infer_type == \"permutation\":\n",
    "            null_values = [] \n",
    "            rng = np.random.default_rng(random_state)\n",
    "            for l_loss, r_loss in zip(l_losses, r_losses):\n",
    "                estimate = l_loss.mean() - r_loss.mean()\n",
    "                paired_loss = np.column_stack([l_loss, r_loss])\n",
    "                null_value = np.array([\n",
    "                    estimate - np.diff(\n",
    "                        rng.permuted(\n",
    "                            paired_loss, \n",
    "                            axis = 1).mean(\n",
    "                            axis = 0)).item() \n",
    "                    for permutation in range(n_permutations)])\n",
    "                null_values.append(null_value)\n",
    "        else:\n",
    "            null_values = None\n",
    "        \n",
    "        self.learner_losses_ = l_losses\n",
    "        self.removed_losses_ = r_losses\n",
    "        self.null_values_ = null_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c34bba9-0e47-4b79-9496-19e54db1f3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inferer(BaseInferer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        learner,\n",
    "        remover,\n",
    "        algorithm,\n",
    "        *,\n",
    "        loss_func = None,\n",
    "        infer_type = None,\n",
    "        n_samples = None,\n",
    "        n_permutations = None,\n",
    "        double_split = None,\n",
    "        perturb_size = None,\n",
    "        random_state = None,\n",
    "        removed_column = None\n",
    "    ):\n",
    "        if algorithm in [\"CRT\", \"HRT\",\"RPT\", \"CPI\"]:\n",
    "            if algorithm  in [\"CRT\", \"HRT\",\"RPT\"]:\n",
    "                if infer_type is None:\n",
    "                    infer_type = \"randomization\"\n",
    "                if n_samples is None:\n",
    "                    n_samples = 2000\n",
    "            else:\n",
    "                if infer_type is None:\n",
    "                    infer_type = \"normality\"\n",
    "                if n_samples is None:\n",
    "                    n_samples = 1\n",
    "                if (infer_type == \"permutation\") and (n_permutations is None):\n",
    "                    n_permutations = 2000\n",
    "            if removed_column is None:\n",
    "                removed_column = self._removed_column(learner, remover)\n",
    "            self.__class__ = CIT\n",
    "            CIT.__init__(\n",
    "                self,\n",
    "                learner, \n",
    "                remover, \n",
    "                algorithm,\n",
    "                loss_func = loss_func,\n",
    "                infer_type = infer_type,\n",
    "                n_samples = n_samples,\n",
    "                n_permutations = n_permutations,\n",
    "                random_state = random_state,\n",
    "                removed_column = removed_column)\n",
    "        elif algorithm in [\"LOCO\", \"BBT\", \"PIE\"]:\n",
    "            if infer_type is None:\n",
    "                infer_type = \"normality\"\n",
    "            if (infer_type == \"permutation\") and (n_permutations is None):\n",
    "                n_permutations = 2000\n",
    "            if algorithm in [\"BBT\", \"PIE\"] and (double_split is None):\n",
    "                double_split = True\n",
    "            self.__class__ = RIT\n",
    "            RIT.__init__(\n",
    "                self,\n",
    "                learner, \n",
    "                remover, \n",
    "                algorithm,\n",
    "                loss_func = loss_func,\n",
    "                infer_type = infer_type,\n",
    "                double_split = double_split,\n",
    "                n_permutations = n_permutations,\n",
    "                perturb_size = perturb_size,\n",
    "                random_state = random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe8dd579-d5eb-469b-b3b1-f4639b50dec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, r2 = gen_xy(\n",
    "        model = \"linear\",\n",
    "        iv_corr = .8,\n",
    "        n_obs= 400)\n",
    "removed_column = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef2dc597-18bd-4863-a0b9-f9eec4685eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold, RepeatedKFold, LeaveOneGroupOut, LeavePGroupsOut\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "splitter = RepeatedKFold(\n",
    "    n_splits = 3, \n",
    "    n_repeats = 4, \n",
    "    random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "819afde1-b2e4-47a9-b5c5-f7e15208ef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = Crosser(\n",
    "    GridSearchCV(\n",
    "            estimator = RandomForestRegressor(max_samples = .5), \n",
    "            param_grid = {\n",
    "                \"max_features\": [3, 6, 9]}, \n",
    "            cv = 4),\n",
    "    cv = splitter)\n",
    "sampler = Crosser(\n",
    "    GridSearchCV(\n",
    "            estimator = RandomForestRegressor(max_samples = .5), \n",
    "            param_grid = {\n",
    "                \"max_features\": [3, 6, 9]}, \n",
    "            cv = 4),\n",
    "    cv = splitter)\n",
    "competitor = Crosser(\n",
    "    GridSearchCV(\n",
    "            estimator = RandomForestRegressor(max_samples = .5), \n",
    "            param_grid = {\n",
    "                \"max_features\": [3, 6, 9]}, \n",
    "            cv = 4),\n",
    "    cv = splitter)\n",
    "_ = learner.fit(X, y)\n",
    "_ = sampler.fit(\n",
    "    np.delete(X, removed_column, axis = 1), X[:,removed_column])\n",
    "_ = competitor.fit(\n",
    "    np.delete(X, removed_column, axis = 1), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c583043a-fc9b-4d0d-8449-8de80e481071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimate</th>\n",
       "      <th>std_error</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.003866</td>\n",
       "      <td>0.8015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.002177</td>\n",
       "      <td>0.001627</td>\n",
       "      <td>0.0950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005256</td>\n",
       "      <td>0.002717</td>\n",
       "      <td>0.9710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.001943</td>\n",
       "      <td>0.002945</td>\n",
       "      <td>0.2580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005732</td>\n",
       "      <td>0.002550</td>\n",
       "      <td>0.9870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.001291</td>\n",
       "      <td>0.002236</td>\n",
       "      <td>0.2840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001342</td>\n",
       "      <td>0.002753</td>\n",
       "      <td>0.6875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.004345</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>0.0935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.002294</td>\n",
       "      <td>0.001933</td>\n",
       "      <td>0.1130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.000249</td>\n",
       "      <td>0.001971</td>\n",
       "      <td>0.4555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.002149</td>\n",
       "      <td>0.001821</td>\n",
       "      <td>0.1165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.004362</td>\n",
       "      <td>0.002454</td>\n",
       "      <td>0.9625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       estimate  std_error  p_value\n",
       "split                              \n",
       "0      0.003124   0.003866   0.8015\n",
       "1     -0.002177   0.001627   0.0950\n",
       "2      0.005256   0.002717   0.9710\n",
       "3     -0.001943   0.002945   0.2580\n",
       "4      0.005732   0.002550   0.9870\n",
       "5     -0.001291   0.002236   0.2840\n",
       "6      0.001342   0.002753   0.6875\n",
       "7     -0.004345   0.003252   0.0935\n",
       "8     -0.002294   0.001933   0.1130\n",
       "9     -0.000249   0.001971   0.4555\n",
       "10    -0.002149   0.001821   0.1165\n",
       "11     0.004362   0.002454   0.9625"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crt = Inferer(\n",
    "    learner, \n",
    "    sampler,\n",
    "    \"CRT\")\n",
    "_ = crt.infer()\n",
    "crt.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6170b866-de7b-464e-a740-5d3bfb1a56ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimate</th>\n",
       "      <th>std_error</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.005910</td>\n",
       "      <td>0.003602</td>\n",
       "      <td>0.050414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.002534</td>\n",
       "      <td>0.001951</td>\n",
       "      <td>0.097009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004985</td>\n",
       "      <td>0.003890</td>\n",
       "      <td>0.900024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.002394</td>\n",
       "      <td>0.003777</td>\n",
       "      <td>0.263137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004518</td>\n",
       "      <td>0.003008</td>\n",
       "      <td>0.933435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.000451</td>\n",
       "      <td>0.003327</td>\n",
       "      <td>0.446092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.000488</td>\n",
       "      <td>0.002594</td>\n",
       "      <td>0.425376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.002817</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.245987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.002747</td>\n",
       "      <td>0.002728</td>\n",
       "      <td>0.843006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000848</td>\n",
       "      <td>0.002619</td>\n",
       "      <td>0.626897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.004019</td>\n",
       "      <td>0.002465</td>\n",
       "      <td>0.051500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.005651</td>\n",
       "      <td>0.003670</td>\n",
       "      <td>0.938202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       estimate  std_error   p_value\n",
       "split                               \n",
       "0     -0.005910   0.003602  0.050414\n",
       "1     -0.002534   0.001951  0.097009\n",
       "2      0.004985   0.003890  0.900024\n",
       "3     -0.002394   0.003777  0.263137\n",
       "4      0.004518   0.003008  0.933435\n",
       "5     -0.000451   0.003327  0.446092\n",
       "6     -0.000488   0.002594  0.425376\n",
       "7     -0.002817   0.004100  0.245987\n",
       "8      0.002747   0.002728  0.843006\n",
       "9      0.000848   0.002619  0.626897\n",
       "10    -0.004019   0.002465  0.051500\n",
       "11     0.005651   0.003670  0.938202"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpi = Inferer(\n",
    "    learner, \n",
    "    sampler,\n",
    "    \"CPI\",\n",
    "    infer_type = \"normality\",\n",
    "    n_samples = 1)\n",
    "_ = cpi.infer()\n",
    "cpi.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28793a73-51aa-4d93-9abf-d42b44adb031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimate</th>\n",
       "      <th>std_error</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007222</td>\n",
       "      <td>0.004592</td>\n",
       "      <td>0.9360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001099</td>\n",
       "      <td>0.002152</td>\n",
       "      <td>0.6765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002354</td>\n",
       "      <td>0.003335</td>\n",
       "      <td>0.7470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.003058</td>\n",
       "      <td>0.002985</td>\n",
       "      <td>0.1530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.008231</td>\n",
       "      <td>0.003825</td>\n",
       "      <td>0.9845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.002125</td>\n",
       "      <td>0.002908</td>\n",
       "      <td>0.2430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000563</td>\n",
       "      <td>0.004096</td>\n",
       "      <td>0.5685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.000322</td>\n",
       "      <td>0.004040</td>\n",
       "      <td>0.4650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.004318</td>\n",
       "      <td>0.002960</td>\n",
       "      <td>0.0775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.001710</td>\n",
       "      <td>0.002504</td>\n",
       "      <td>0.7610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.000447</td>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.4335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.002841</td>\n",
       "      <td>0.003844</td>\n",
       "      <td>0.7640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       estimate  std_error  p_value\n",
       "split                              \n",
       "0      0.007222   0.004592   0.9360\n",
       "1      0.001099   0.002152   0.6765\n",
       "2      0.002354   0.003335   0.7470\n",
       "3     -0.003058   0.002985   0.1530\n",
       "4      0.008231   0.003825   0.9845\n",
       "5     -0.002125   0.002908   0.2430\n",
       "6      0.000563   0.004096   0.5685\n",
       "7     -0.000322   0.004040   0.4650\n",
       "8     -0.004318   0.002960   0.0775\n",
       "9      0.001710   0.002504   0.7610\n",
       "10    -0.000447   0.002427   0.4335\n",
       "11     0.002841   0.003844   0.7640"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpi = Inferer(\n",
    "    learner, \n",
    "    sampler,\n",
    "    \"CPI\",\n",
    "    infer_type = \"permutation\",\n",
    "    n_samples = 1)\n",
    "_ = cpi.infer()\n",
    "cpi.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86156ca0-4e50-4006-a1ed-17930646073a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimate</th>\n",
       "      <th>std_error</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000091</td>\n",
       "      <td>0.006996</td>\n",
       "      <td>0.494809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.004583</td>\n",
       "      <td>0.008155</td>\n",
       "      <td>0.287053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005217</td>\n",
       "      <td>0.007356</td>\n",
       "      <td>0.760899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.001720</td>\n",
       "      <td>0.006318</td>\n",
       "      <td>0.392704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.009275</td>\n",
       "      <td>0.006387</td>\n",
       "      <td>0.926767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.000466</td>\n",
       "      <td>0.007976</td>\n",
       "      <td>0.476704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.000415</td>\n",
       "      <td>0.007899</td>\n",
       "      <td>0.479056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.001451</td>\n",
       "      <td>0.005880</td>\n",
       "      <td>0.402575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.007818</td>\n",
       "      <td>0.007141</td>\n",
       "      <td>0.136804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.009155</td>\n",
       "      <td>0.501642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.009506</td>\n",
       "      <td>0.005278</td>\n",
       "      <td>0.035842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.004616</td>\n",
       "      <td>0.004934</td>\n",
       "      <td>0.174760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       estimate  std_error   p_value\n",
       "split                               \n",
       "0     -0.000091   0.006996  0.494809\n",
       "1     -0.004583   0.008155  0.287053\n",
       "2      0.005217   0.007356  0.760899\n",
       "3     -0.001720   0.006318  0.392704\n",
       "4      0.009275   0.006387  0.926767\n",
       "5     -0.000466   0.007976  0.476704\n",
       "6     -0.000415   0.007899  0.479056\n",
       "7     -0.001451   0.005880  0.402575\n",
       "8     -0.007818   0.007141  0.136804\n",
       "9      0.000038   0.009155  0.501642\n",
       "10    -0.009506   0.005278  0.035842\n",
       "11    -0.004616   0.004934  0.174760"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loco = Inferer(\n",
    "    learner, \n",
    "    competitor,\n",
    "    \"LOCO\",\n",
    "    infer_type = \"normality\")\n",
    "_ = loco.infer()\n",
    "loco.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2ae58ae-4fee-4228-ae63-f5d658fef0d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimate</th>\n",
       "      <th>std_error</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000091</td>\n",
       "      <td>0.007094</td>\n",
       "      <td>0.4860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.004583</td>\n",
       "      <td>0.008061</td>\n",
       "      <td>0.2870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005217</td>\n",
       "      <td>0.007450</td>\n",
       "      <td>0.7670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.001720</td>\n",
       "      <td>0.006210</td>\n",
       "      <td>0.3950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.009275</td>\n",
       "      <td>0.006342</td>\n",
       "      <td>0.9280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.000466</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.4610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.000415</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.4890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.001451</td>\n",
       "      <td>0.005801</td>\n",
       "      <td>0.4020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.007818</td>\n",
       "      <td>0.007046</td>\n",
       "      <td>0.1395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.009073</td>\n",
       "      <td>0.5055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.009506</td>\n",
       "      <td>0.005358</td>\n",
       "      <td>0.0420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.004616</td>\n",
       "      <td>0.004918</td>\n",
       "      <td>0.1730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       estimate  std_error  p_value\n",
       "split                              \n",
       "0     -0.000091   0.007094   0.4860\n",
       "1     -0.004583   0.008061   0.2870\n",
       "2      0.005217   0.007450   0.7670\n",
       "3     -0.001720   0.006210   0.3950\n",
       "4      0.009275   0.006342   0.9280\n",
       "5     -0.000466   0.007800   0.4610\n",
       "6     -0.000415   0.007778   0.4890\n",
       "7     -0.001451   0.005801   0.4020\n",
       "8     -0.007818   0.007046   0.1395\n",
       "9      0.000038   0.009073   0.5055\n",
       "10    -0.009506   0.005358   0.0420\n",
       "11    -0.004616   0.004918   0.1730"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loco = Inferer(\n",
    "    learner, \n",
    "    competitor,\n",
    "    \"LOCO\",\n",
    "    infer_type = \"permutation\")\n",
    "_ = loco.infer()\n",
    "loco.summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a80f7a",
   "metadata": {},
   "source": [
    "# test combine p-values methods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5301d846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test p-values: [0.936  0.6765 0.747  0.153  0.9845 0.243  0.5685 0.465  0.0775 0.761\n",
      " 0.4335 0.764 ]\n",
      "count of p-values: 12\n"
     ]
    }
   ],
   "source": [
    "test_pvalues = cpi.summarize().loc[:, \"p_value\"].to_numpy()\n",
    "print(f'test p-values: {test_pvalues}')\n",
    "cv_n = len(test_pvalues)\n",
    "print(f'count of p-values: {cv_n}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f781b6d5",
   "metadata": {},
   "source": [
    "## gmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef47db12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2499864591216037"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.e * gmean(test_pvalues, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51d7cfea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimate</th>\n",
       "      <th>std_error</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.003306</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   estimate  std_error  p_value\n",
       "0  0.001146   0.003306      1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpi.summarize(agg_method = \"gmean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c53ba1",
   "metadata": {},
   "source": [
    "## median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6f702b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.245"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*np.median(test_pvalues, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f6fcc40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimate</th>\n",
       "      <th>std_error</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.003306</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   estimate  std_error  p_value\n",
       "0  0.001146   0.003306      1.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpi.summarize(agg_method = \"median\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104790b7",
   "metadata": {},
   "source": [
    "## Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2053de49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9179999999999999"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_n / 2.*np.partition(test_pvalues, 1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a349a2d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimate</th>\n",
       "      <th>std_error</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.003306</td>\n",
       "      <td>0.918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   estimate  std_error  p_value\n",
       "0  0.001146   0.003306    0.918"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpi.summarize(agg_method = \"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03daadf1",
   "metadata": {},
   "source": [
    "## min "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab15fb72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9299999999999999"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_n*np.min(test_pvalues, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49b470dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimate</th>\n",
       "      <th>std_error</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.003306</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   estimate  std_error  p_value\n",
       "0  0.001146   0.003306     0.93"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpi.summarize(agg_method = \"min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7681ff",
   "metadata": {},
   "source": [
    "## hmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6acb5275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.173393766783454"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.e * np.log(cv_n) * hmean(test_pvalues, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e3e1baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimate</th>\n",
       "      <th>std_error</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.003306</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   estimate  std_error  p_value\n",
       "0  0.001146   0.003306      1.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpi.summarize(agg_method = \"hmean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebeebf2",
   "metadata": {},
   "source": [
    "## hommel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa914021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8450235497835497"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const = np.sum(1. / (np.arange(cv_n) + 1.))\n",
    "order_const = const * (cv_n / (np.arange(cv_n) + 1.))\n",
    "np.min(np.sort(test_pvalues) * order_const)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3dcd87e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimate</th>\n",
       "      <th>std_error</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.003306</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   estimate  std_error  p_value\n",
       "0  0.001146   0.003306      1.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpi.summarize(agg_method = \"hommel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a74f73",
   "metadata": {},
   "source": [
    "## cauchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "47f4a706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8416490608232399"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 =np.mean(np.tan((.5 - test_pvalues)*np.pi))\n",
    ".5 - np.arctan(t0) / np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "620adcf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimate</th>\n",
       "      <th>std_error</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.003306</td>\n",
       "      <td>0.841649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   estimate  std_error   p_value\n",
       "0  0.001146   0.003306  0.841649"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpi.summarize(agg_method = \"cauchy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
