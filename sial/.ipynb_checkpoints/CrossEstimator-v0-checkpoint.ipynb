{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "59662b87-f10b-4fd6-8460-83f8b2bb53cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import check_cv\n",
    "from sklearn.base import is_classifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import get_scorer, check_scoring\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from scipy.special import xlogy\n",
    "from scipy.stats import multinomial\n",
    "from numpy.random import choice, permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3c096675-d58c-4854-9c74-01eb271a49ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEstimator():\n",
    "    def __init__(\n",
    "        self,\n",
    "        estimator,\n",
    "        cv = None\n",
    "    ):\n",
    "        self.estimator = estimator\n",
    "        self.cv = cv\n",
    "\n",
    "    def fit(\n",
    "        self, \n",
    "        X, \n",
    "        y\n",
    "    ):\n",
    "        cv = check_cv(self.cv, y, classifier = is_classifier(self.estimator))\n",
    "        cv_indexes = []\n",
    "        estimators = []\n",
    "        for train_index, test_index in cv.split(X):     \n",
    "            estimator = clone(self.estimator)\n",
    "            _ = estimator.fit(X[train_index,], y[train_index])\n",
    "            if hasattr(estimator, \"best_estimator_\"):\n",
    "                estimator = estimator.best_estimator_\n",
    "            estimators.append(estimator)               \n",
    "            cv_indexes.append((train_index, test_index))\n",
    "        self.X, self.y = X.copy(), y.copy()\n",
    "        self.estimators_ = estimators\n",
    "        self.cv_indexes_ = cv_indexes\n",
    "        if is_classifier(self.estimator):\n",
    "            label_binarizer = LabelBinarizer()\n",
    "            _ = label_binarizer.fit(y)\n",
    "            self.label_binarizer_ = label_binarizer\n",
    "        return self\n",
    "\n",
    "    def predict(\n",
    "        self, \n",
    "        X = None\n",
    "    ):\n",
    "        if X is None:\n",
    "            X = self.X\n",
    "            preds = []\n",
    "            for (train_index, test_index), estimator in zip(\n",
    "                self.cv_indexes_, self.estimators_):\n",
    "                pred = estimator.predict(X[test_index,])\n",
    "                preds.append(pred)\n",
    "            return preds\n",
    "        else:\n",
    "            preds = np.array(\n",
    "                [estimator.predict(X) \n",
    "                 for estimator in self.estimators_])\n",
    "            if is_classifier(self.estimator):\n",
    "                pred = np.apply_along_axis(\n",
    "                    lambda x: np.argmax(np.bincount(x)),\n",
    "                    axis = 0,\n",
    "                    arr = preds)\n",
    "            else:\n",
    "                pred = preds.mean(axis = 0)\n",
    "            return pred\n",
    "\n",
    "    def predict_proba(\n",
    "        self, \n",
    "        X = None\n",
    "    ):\n",
    "        if X is None:\n",
    "            X = self.X\n",
    "            preds = []\n",
    "            for (train_index, test_index), estimator in zip(\n",
    "                self.cv_indexes_, self.estimators_):\n",
    "                pred = estimator.predict_proba(X[test_index,])\n",
    "                preds.append(pred)\n",
    "            return preds\n",
    "        else:\n",
    "            preds = np.array(\n",
    "                [estimator.predict_proba(X) \n",
    "                 for estimator in self.estimators_])\n",
    "            pred = preds.mean(axis = 0)\n",
    "            return pred\n",
    "\n",
    "    def predict_log_proba(\n",
    "        self, \n",
    "        X = None\n",
    "    ):\n",
    "        if X is None:\n",
    "            X = self.X\n",
    "            preds = []\n",
    "            for (train_index, test_index), estimator in zip(\n",
    "                self.cv_indexes_, self.estimators_):\n",
    "                pred = estimator.predict_log_proba(X[test_index,])\n",
    "                preds.append(pred)\n",
    "            return preds\n",
    "        else:\n",
    "            preds = np.array(\n",
    "                [estimator.predict_log_proba(X) \n",
    "                 for estimator in self.estimators_])\n",
    "            pred = preds.mean(axis = 0)\n",
    "            return pred\n",
    "            \n",
    "    def decision_function(\n",
    "        self, \n",
    "        X = None\n",
    "    ):\n",
    "        if X is None:\n",
    "            X = self.X\n",
    "            preds = []\n",
    "            for (train_index, test_index), estimator in zip(\n",
    "                self.cv_indexes_, self.estimators_):\n",
    "                pred = estimator.decision_function(X[test_index,])\n",
    "                preds.append(pred)\n",
    "            return preds\n",
    "        else:\n",
    "            preds = np.array(\n",
    "                [estimator.decision_function(X) \n",
    "                 for estimator in self.estimators_])\n",
    "            pred = preds.mean(axis = 0)\n",
    "            return pred\n",
    "            \n",
    "    def reply(\n",
    "        self,\n",
    "        y = None,\n",
    "        binarize = False\n",
    "    ):\n",
    "        if y is None:\n",
    "            y = self.y\n",
    "            cv_indexes = self.cv_indexes_\n",
    "            facts = []\n",
    "            for train_index, test_index in cv_indexes:\n",
    "                fact = y[test_index]\n",
    "                if is_classifier(self.estimator):\n",
    "                    if binarize is True:\n",
    "                        fact = self.label_binarizer_.transform(fact)\n",
    "                        if fact.shape[1] == 1:\n",
    "                            fact = np.append(1 - fact, fact, axis=1)\n",
    "                facts.append(fact)\n",
    "            return facts\n",
    "        else:\n",
    "            fact = y\n",
    "            if is_classifier(self.estimator):\n",
    "                if binarize is True:\n",
    "                    fact = self.label_binarizer_.transform(fact)\n",
    "                    if fact.shape[1] == 1:\n",
    "                        fact = np.append(1 - fact, fact, axis=1)\n",
    "            return fact\n",
    "\n",
    "    def quantify(\n",
    "        self,\n",
    "        fact = None,\n",
    "        pred = None,\n",
    "        loss_func = None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        if loss_func is None:\n",
    "            if is_classifier(self.estimator):\n",
    "                loss_func = \"log_loss\"\n",
    "            else:\n",
    "                loss_func == \"mean_squared_error\"\n",
    "        \n",
    "        if loss_func == \"log_loss\":\n",
    "            def log_loss(fact, pred, **kwargs):\n",
    "                eps = np.finfo(pred.dtype).eps\n",
    "                pred = np.clip(pred, eps, 1 - eps)\n",
    "                loss = -xlogy(fact, pred).sum(axis=1)\n",
    "                return loss\n",
    "            loss_func = log_loss\n",
    "            \n",
    "        if loss_func == \"mean_squared_error\":\n",
    "            def mean_squared_error(fact, pred, **kwargs):\n",
    "                loss = (fact - pred)**2\n",
    "                return loss\n",
    "            loss_func = mean_squared_error\n",
    "\n",
    "        if fact is None and pred is None:\n",
    "            if loss_func.__name__ in [\"log_loss\"]:\n",
    "                facts = self.reply(binarize = True)\n",
    "                preds = self.predict_proba()\n",
    "            else:\n",
    "                facts = self.reply()\n",
    "                preds = self.predict()\n",
    "            losses = []\n",
    "            for fact, pred in zip(facts, preds):\n",
    "                loss = loss_func(fact, pred, **kwargs)\n",
    "                losses.append(loss)\n",
    "            return losses\n",
    "        else:\n",
    "            loss = loss_func(fact, pred, **kwargs)\n",
    "            return loss\n",
    "    \n",
    "    def sample(\n",
    "        self,\n",
    "        X = None):\n",
    "        if X is None:\n",
    "            rvs = []\n",
    "            if is_classifier(self.estimator):\n",
    "                preds = self.predict_proba()\n",
    "                for pred in preds:\n",
    "                    rv = np.apply_along_axis(\n",
    "                        lambda pred_i: multinomial.rvs(\n",
    "                            1, pred_i),\n",
    "                        axis = 1,\n",
    "                        arr = pred)\n",
    "                    rv = self.label_binarizer_.inverse_transform(rv)\n",
    "                    rvs.append(rv)\n",
    "            else:\n",
    "                preds = self.predict()\n",
    "                facts = self.reply()\n",
    "                for pred, fact in zip(preds, facts):\n",
    "                    res = fact - pred\n",
    "                    rv = pred + permutation(res)\n",
    "                    rvs.append(rv)\n",
    "            return rvs\n",
    "        else:\n",
    "            if is_classifier(self.estimator):\n",
    "                pred = self.predict_proba(X)\n",
    "                rv = np.apply_along_axis(\n",
    "                    lambda pred_i: multinomial.rvs(\n",
    "                        1, pred_i),\n",
    "                    axis = 1,\n",
    "                    arr = pred)\n",
    "                rv = self.label_binarizer_.inverse_transform(rv)\n",
    "            else:\n",
    "                preds = self.predict()\n",
    "                facts = self.reply()\n",
    "                res = np.concatenate(\n",
    "                    [fact - pred for fact, pred in zip(facts, preds)])\n",
    "                pred = self.predict(X)\n",
    "                rv = pred + choice(res, len(pred))\n",
    "            return rv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a43bbdcd-f7af-4094-ba90-3ef90af877d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X, y = datasets.load_diabetes(return_X_y=True)\n",
    "X, y = X[1:150,], y[1:150]\n",
    "lasso = Lasso(\n",
    "    random_state=0, \n",
    "    max_iter=10000)\n",
    "alphas = np.logspace(-4, -0.5, 30)\n",
    "tuned_parameters = [{\"alpha\": alphas}]\n",
    "n_folds = 5\n",
    "rgs = GridSearchCV(lasso, tuned_parameters, cv=n_folds)\n",
    "rkf = RepeatedKFold(n_splits = 5, n_repeats = 1)\n",
    "learner = CrossEstimator(rgs, rkf)\n",
    "_ = learner.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "247b59de-34ac-4778-acb2-179605fdeaa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 81.79951213, 161.6800473 , 148.64169974, 134.95923814,\n",
       "        110.52155513, 184.41442571,  94.2748343 , 202.97900428,\n",
       "        158.91327041, 103.18708296, 127.08650977, 171.59914465,\n",
       "        118.82741332,  92.43436574, 160.04057161,  87.86196425,\n",
       "        215.55241897, 117.44655629, 181.81597251, 187.58215695,\n",
       "        204.98778484, 193.61613087, 117.29315557, 192.62642813,\n",
       "        217.65890634,  79.96491807, 214.75271249, 203.34423123,\n",
       "        176.11130208, 109.66448643]),\n",
       " array([147.35470348, 101.59854541, 157.9727859 , 167.3328732 ,\n",
       "        130.81452171, 207.30204143, 238.28949885,  88.67952429,\n",
       "        135.66199525,  84.96584325, 223.82053542,  86.13172649,\n",
       "        172.05258892,  75.81277023, 150.39327435,  43.34627297,\n",
       "        195.78494798, 147.96725815, 164.71956196, 125.17577197,\n",
       "        154.81333812, 156.55679726, 184.84453888,  93.90923675,\n",
       "         74.11417455, 249.05918044, 237.29317963, 121.8149317 ,\n",
       "        229.46646234, 188.27556924]),\n",
       " array([163.09279532, 135.13700491,  86.21886913, 119.14622917,\n",
       "        282.89039522, 186.70569761, 226.60138831, 149.0634864 ,\n",
       "        146.66754917, 152.44492343, 135.68296752,  74.01249639,\n",
       "         97.21761899,  54.02354199, 110.39949763, 189.87982127,\n",
       "        111.05039963, 118.08058298, 169.23668601, 156.08571415,\n",
       "        111.56841411,  74.75517423, 204.27345199, 123.73163603,\n",
       "        172.91333772, 144.2413128 , 301.87199202, 199.13761724,\n",
       "        161.32207475,  73.47311384]),\n",
       " array([ 79.33135728, 102.76485644, 125.40719872, 103.27264607,\n",
       "        159.40865957, 171.32917582, 144.83076798,  90.03412883,\n",
       "         85.73158326,  94.96222244, 181.86862655, 167.91153421,\n",
       "        131.10953826, 103.42105193, 138.06529522, 146.36491576,\n",
       "        151.91518703, 129.07123219, 158.3397703 ,  89.05810036,\n",
       "        113.26827447, 141.03426269, 140.27151898, 107.04148729,\n",
       "        176.39060146, 145.79130456,  83.23889125, 262.48041813,\n",
       "        150.22223494, 166.82948884]),\n",
       " array([136.16462508, 130.20120823, 239.57455091, 121.53874242,\n",
       "        237.96224225, 159.41326179, 136.67741244, 168.38138064,\n",
       "        126.2179295 , 128.05773557, 134.37453019,  64.03047689,\n",
       "        168.97795625, 222.37068381, 142.2285641 , 211.00428091,\n",
       "        112.44653408,  47.54874067,  81.85916714, 221.33384277,\n",
       "        224.34992121, 113.05894093,  23.34288338, 152.73327945,\n",
       "        205.9124689 , 219.27336821, 101.87421606, 158.15955761,\n",
       "        246.13381235])]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5495ea6b-35e0-4197-90bd-f325d3fd8556",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold, RepeatedKFold\n",
    "rkf = RepeatedKFold(n_splits = 5, n_repeats = 1)\n",
    "iris = datasets.load_iris()\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    "svc = svm.SVC(probability = True)\n",
    "clf = GridSearchCV(svc, parameters)\n",
    "learner = CrossEstimator(clf, rkf)\n",
    "_ = learner.fit(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b113301b-c1f8-411e-815e-ab0b3b6916cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.sample(iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "0da0854b-84cf-4a0d-9ef4-4af0edea40b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (2282326014.py, line 21)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[329], line 21\u001b[0;36m\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "class CIT():\n",
    "    def __init__(\n",
    "        self, \n",
    "        learner,\n",
    "        remover,\n",
    "        loss_func = None\n",
    "    ):\n",
    "        self.learner = learner\n",
    "        self.remover = remover\n",
    "        self.loss_func = loss_func\n",
    "\n",
    "    def infer(\n",
    "        self\n",
    "    ):\n",
    "        learner_facts = learner.reply()\n",
    "        learner_preds = learner.predict()\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4faebd8c-9380-4acf-a7a1-8c7f824501ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdb19da0-4da5-4072-9dbe-8c4d676d6948",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "704218f3-2e49-4471-b627-4182068f26a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 1, 2, 2, 2]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 2, 1, 1, 2, 1,\n",
       "        1, 2, 2, 2, 2, 2, 2, 2]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1,\n",
       "        1, 0, 1, 2, 2, 2, 2, 2]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "929b0d14-ea2f-49e6-9df7-f241dd8e7767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.03047872, 0.03371168, 0.04622066, 0.04113181, 0.0199701 ,\n",
       "        0.05687095, 0.04799187, 0.03460839, 0.05022425, 0.03405066,\n",
       "        0.17229335, 0.25204089, 0.08572921, 0.34540535, 0.0699074 ,\n",
       "        0.06635565, 0.03908081, 0.05198329, 0.05938119, 0.00350774,\n",
       "        0.01521838, 0.04411749, 0.09087275, 0.01507744, 0.21357253,\n",
       "        0.02099946, 0.09016782, 0.11047597, 0.02437719, 0.1494673 ]),\n",
       " array([0.03147789, 0.04726225, 0.03124575, 0.03744061, 0.08696101,\n",
       "        0.0271521 , 0.02547536, 0.04119737, 0.03261583, 0.05335157,\n",
       "        0.05107176, 0.15538328, 0.03916825, 0.05364395, 0.18464269,\n",
       "        0.753597  , 0.02594374, 0.0583422 , 0.08509803, 0.0285936 ,\n",
       "        0.05989299, 0.00355041, 0.01405706, 0.13744988, 0.02667314,\n",
       "        0.5064949 , 0.01468881, 0.01553904, 0.00971281, 0.04256084]),\n",
       " array([0.0543839 , 0.02965617, 0.04939194, 0.02346165, 0.07150733,\n",
       "        0.05849003, 0.05560787, 0.02689555, 0.06556507, 0.03648379,\n",
       "        0.18724785, 0.11322675, 0.04016516, 0.04466887, 0.01650383,\n",
       "        0.02402028, 0.08315959, 0.03092875, 1.32003308, 0.12381202,\n",
       "        0.02920357, 0.00424502, 0.19088346, 0.02184   , 0.55395778,\n",
       "        0.51649304, 0.02648396, 0.68961687, 0.23099512, 0.11706721]),\n",
       " array([2.80494431e-02, 2.11544311e-02, 3.43513242e-02, 5.70914030e-02,\n",
       "        1.83172373e-02, 3.47232853e-02, 2.52003495e-02, 1.17491066e-01,\n",
       "        4.70941230e-02, 8.73992730e-02, 2.34369856e-02, 3.74532138e-01,\n",
       "        2.41515650e-02, 8.07932041e-01, 1.99072135e-02, 4.01759789e-02,\n",
       "        9.64569651e-02, 2.60171581e-02, 8.80156417e-03, 6.42133915e-03,\n",
       "        4.34407690e-03, 3.71287236e-06, 1.38261697e-03, 4.88733089e-01,\n",
       "        8.19392717e-03, 5.34746296e-02, 4.20420146e-03, 5.75726560e-02,\n",
       "        8.87462443e-03, 5.38379580e-02]),\n",
       " array([0.0576265 , 0.04706338, 0.05854596, 0.05771399, 0.01994094,\n",
       "        0.04021383, 0.06984572, 0.01490579, 0.09661936, 0.04140492,\n",
       "        0.02148441, 0.11023849, 0.07382542, 0.04495729, 0.03736083,\n",
       "        0.02560116, 0.02830313, 0.74840774, 0.0991174 , 0.0248504 ,\n",
       "        0.03336183, 0.02560493, 0.18468652, 0.03587709, 0.62868037,\n",
       "        0.01459138, 0.06018087, 0.02693012, 0.58990991, 0.00635009])]"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.quantify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "f7107bcc-84e9-45ef-bfa5-39a8f04d9b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.apply_along_axis(\n",
    "                lambda x: np.argmax(np.bincount(x)),\n",
    "                axis=0,\n",
    "                arr=learner.predict(iris.data),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "32348049-0ed6-4282-8b9a-3d5a3be7b9d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.05645564, 0.05238995, 0.03368536, 0.05384512, 0.05161804,\n",
       "        0.04756854, 0.02234061, 0.02452637, 0.03387893, 0.07033476,\n",
       "        0.07788535, 0.04866863, 0.1046384 , 0.06914687, 0.04841894,\n",
       "        0.04495078, 0.07118952, 0.02451234, 0.06079586, 0.03506321,\n",
       "        0.02836699, 0.08203701, 0.06065754, 0.04027421, 0.04471997,\n",
       "        0.02299849, 0.00648436, 0.01445789, 0.00856427, 0.14839065,\n",
       "        0.02044827, 0.02350801, 0.00827815, 0.01438462, 0.0348732 ,\n",
       "        0.0050696 , 0.0394479 , 0.00631385, 0.02726235, 0.00327092,\n",
       "        0.00959646, 0.08875323, 0.01586876, 0.00797441, 0.0354622 ,\n",
       "        0.02767817, 0.01763332, 0.01074017, 0.12976665, 0.02277979]),\n",
       " array([0.02837371, 0.03534768, 0.03498755, 0.03756079, 0.03942477,\n",
       "        0.06382299, 0.02598236, 0.01590016, 0.03017132, 0.02642951,\n",
       "        0.01289047, 0.08525378, 0.07070279, 0.06377964, 0.06635004,\n",
       "        0.01645138, 0.02134683, 0.04700615, 0.03857348, 0.02531727,\n",
       "        0.09849957, 0.03774065, 0.0549704 , 0.03027444, 0.02655606,\n",
       "        0.02863289, 0.03487748, 0.01608108, 0.02452025, 0.05311717,\n",
       "        0.06576624, 0.13238627, 0.04296326, 0.04186691, 0.03779934,\n",
       "        0.01467585, 0.0100785 , 0.02319519, 0.05948424, 0.07623616,\n",
       "        0.06782231, 0.00546695, 0.03737471, 0.02270353, 0.05045342,\n",
       "        0.05159821, 0.04370946, 0.04012687, 0.26294567, 0.04757278])]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.get_losses(loss_func = \"log_loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798c2d31-4bf3-43bd-9654-bc547cafdd0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
